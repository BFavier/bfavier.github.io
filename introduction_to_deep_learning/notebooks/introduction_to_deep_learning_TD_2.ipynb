{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Callable, Iterable\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I) Déplacer un Tensor sur GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on peut dénombrer les GPU disponibles avec:\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on CPU:\n",
      "tensor([[0.9662, 0.6436, 0.8573],\n",
      "        [0.1511, 0.5787, 0.7913],\n",
      "        [0.3032, 0.5021, 0.9905]])\n",
      "on GPU:\n",
      "tensor([[0.6923, 0.9728, 0.2130],\n",
      "        [0.0356, 0.0720, 0.6024],\n",
      "        [0.0308, 0.4671, 0.6357]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Le 'device' sur lequel un tenseur est stocké peut être défini à la création\n",
    "# l'index après 'cuda' correspond à l'index du GPU si plusieurs GPUs sont disponibles\n",
    "print(\"on CPU:\")\n",
    "print(torch.rand(3, 3, device=\"cpu\"))\n",
    "print(\"on GPU:\")\n",
    "print(torch.rand(3, 3, device=\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before copying on GPU:\n",
      "cpu\n",
      "after copying on GPU:\n",
      "cpu \t cuda:0\n"
     ]
    }
   ],
   "source": [
    "# on peut copier un tenseur sur un nouveau 'device' avec la méthode 'to'\n",
    "print(\"before copying on GPU:\")\n",
    "t = torch.rand(3, 3)\n",
    "print(t.device)\n",
    "print(\"after copying on GPU:\")\n",
    "moved = t.to(\"cuda:0\")\n",
    "print(t.device, \"\\t\", moved.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# il existe des méthode raccourcis\n",
    "print(torch.rand(3, 3, device=\"cpu\").cuda().device)\n",
    "print(torch.rand(3, 3, device=\"cuda:0\").cpu().device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n"
     ]
    }
   ],
   "source": [
    "# on ne peut pas faire une opératio entre deux tensuers sur des 'device' différents\n",
    "try:\n",
    "    t * moved\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II) Déplacer un Module sur GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on peut définir le 'device' des Modules built-in de pytorch\n",
    "module = torch.nn.Linear(3, 5, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Linear' object has no attribute 'device'\n"
     ]
    }
   ],
   "source": [
    "# il n'dxiste cependant pas d'attribut 'device'\n",
    "try:\n",
    "    module.device\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# les objets Module ont aussi une méthode 'to', qui modifie l'objet 'inplace'\n",
    "moved = module.to(\"cuda:0\")\n",
    "print(moved is module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# moving a module moves all it's parameters\n",
    "for p in module.parameters():\n",
    "    print(p.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III) Les convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "# La couche de convolution 2D est définie dans le namespace 'torch.nn'\n",
    "conv = torch.nn.Conv2d(in_channels=3, out_channels=5, kernel_size=(3, 3), stride=(1, 1))\n",
    "print(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 254, 254])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# par défaut la convolution est appliquée sans padding, ce qui réduit la taille des featuremaps de sortie\n",
    "conv(torch.rand(10, 3, 256, 256)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Le kwarg padding=\"same\" permet de maintenir la taille de la feature map.\n",
    "conv = torch.nn.Conv2d(in_channels=3, out_channels=5, kernel_size=(3, 3), stride=(1, 1), padding=\"same\")\n",
    "print(conv(torch.rand(10, 3, 256, 256)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice I\n",
    "\n",
    "Définir et entraîner un modèle de classification d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(\"../datasets/CIFAR10/CIFAR-10.npy\")\n",
    "y = np.load(\"../datasets/CIFAR10/CIFAR-10-labels.npy\")\n",
    "labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(*args: tuple[np.ndarray], fracs: tuple[float] = (0.7, 0.15, 0.15)) -> list[tuple[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    split data in \n",
    "    \"\"\"\n",
    "    total = sum(fracs)\n",
    "    fracs = tuple(f/total for f in fracs)\n",
    "    L = len(args[0])\n",
    "    indexes = np.random.permutation(L)\n",
    "    start = 0\n",
    "    results = []\n",
    "    for f in fracs:\n",
    "        end = start + int(f*L)\n",
    "        results.append(tuple(array[indexes[start:end]] for array in args))\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = test_data\n",
    "f, axes = plt.subplots(figsize=[10, 10], nrows=3, ncols=3)\n",
    "i = 0\n",
    "for axs in axes:\n",
    "    for ax in axs:\n",
    "        ax.imshow(x_test[i].transpose(1, 2, 0))\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(labels[y_test[i]])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    returns the accuracy metric of a prediction\n",
    "    \"\"\"\n",
    "    assert predicted.shape == target.shape\n",
    "    return torch.sum(predicted == target).detach().cpu().item()/len(target)\n",
    "\n",
    "def inputs_to_tensor(x) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    converts an image array input into tensor\n",
    "    \"\"\"\n",
    "    return torch.tensor(x/255., dtype=torch.float32)\n",
    "\n",
    "def target_to_tensors(y: np.ndarray) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    converts a target numpy array to tensor\n",
    "    \"\"\"\n",
    "    return torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "def arrays_to_tensors(x: np.ndarray, y: np.ndarray) -> tuple[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    transforms numpy arrays to tensors\n",
    "    \"\"\"\n",
    "    return (inputs_to_tensor(x), target_to_tensors(y))\n",
    "\n",
    "class batchifyer:\n",
    "    \"\"\"\n",
    "    transforms numpy arrays into batches of torch tensor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args: tuple[np.ndarray], n_batches: int = 1, batch_size: int = 100):\n",
    "        self.args = args\n",
    "        self.n_batches = n_batches\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.get_batches()\n",
    "\n",
    "    def get_batches(self) -> Iterable[torch.Tensor]:\n",
    "        L = len(self.args[0])\n",
    "        indexes = np.random.permutation(L)\n",
    "        for i in range(self.n_batches):\n",
    "            x, y = (array[indexes[i*self.batch_size:(i+1)*self.batch_size]] for array in self.args)\n",
    "            yield arrays_to_tensors(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A block is a set of convolution/max pooling/activation/batch normalization\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, activation: Callable = torch.relu, kernel_size: tuple[int] = (3, 3), pool: tuple[int, int] = (2, 2)):\n",
    "        super().__init__()\n",
    "        self.convolution = torch.nn.Conv2d(in_features, out_features, kernel_size, (1, 1), padding=\"same\")\n",
    "        self.pool = torch.nn.MaxPool2d(pool)\n",
    "        self.activation = activation\n",
    "        self.batch_norm = torch.nn.BatchNorm2d(out_features)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.batch_norm(self.activation(self.pool(self.convolution(X))))\n",
    "\n",
    "\n",
    "class ImageClassifier(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    An Image classifier is a CNN that classifies Images\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features: int, n_classes: int, features: list[int], activation: Callable = torch.relu, kernel_size: tuple[int] = (3, 3), pool: tuple[int, int] = 2):\n",
    "        super().__init__()\n",
    "        self.blocks = torch.nn.ModuleList()\n",
    "        for out_features in features:\n",
    "            self.blocks.append(Block(in_features, out_features, activation, kernel_size, pool))\n",
    "            in_features = out_features\n",
    "        self.output = torch.nn.Conv2d(out_features, n_classes, kernel_size=(1, 1), padding=\"same\")\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : torch.Tensor\n",
    "            tensor of floats of shape (N, C, H, W)\n",
    "        \"\"\"\n",
    "        X = X.to(self.device)\n",
    "        for block in self.blocks:\n",
    "            X = block(X)\n",
    "        X = self.output(X)\n",
    "        N, C, H, W = X.shape\n",
    "        return X.reshape(N, C, -1).mean(dim=-1)\n",
    "\n",
    "    def predict(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        perform a prediction of the model\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            Y = self(X)\n",
    "        return Y.max(dim=1).indices\n",
    "    \n",
    "    def loss(self, X: torch.Tensor, Y: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        loss of the model\n",
    "        \"\"\"\n",
    "        y_pred = self(X)\n",
    "        return F.cross_entropy(y_pred, Y.to(y_pred.device))\n",
    "    \n",
    "    def metric(self, X: torch.Tensor, Y: torch.Tensor):\n",
    "        \"\"\"\n",
    "        metric of the model\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy(y_pred, Y.to(y_pred.device))\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return self.output.weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model: torch.nn.Module, optimizer: torch.optim.Optimizer, train_data: Iterable[tuple[torch.Tensor]], val_data: Iterable[tuple[torch.Tensor]], n_steps: int = 1000, patience: int = 100, keep_best: bool = True):\n",
    "    \"\"\"\n",
    "    train the model for the specified number of steps, or untilearly stopping\n",
    "    \"\"\"\n",
    "    best_state = deepcopy(model.state_dict())\n",
    "    best_step = 0\n",
    "    best_metric = 0.\n",
    "    try:\n",
    "        for step in range(n_steps):\n",
    "            optimizer.zero_grad()\n",
    "            # train loss\n",
    "            model.train()\n",
    "            losses = []\n",
    "            for x, y in train_data:\n",
    "                loss = model.loss(x, y)\n",
    "                loss.backward()\n",
    "                losses.append(loss.item())\n",
    "            loss = sum(losses)/len(losses)\n",
    "            # val metric\n",
    "            model.eval()\n",
    "            metrics = []\n",
    "            for x, y in val_data:\n",
    "                metrics.append(model.metric(x, y))\n",
    "            metric = sum(metrics) / len(metrics)\n",
    "            # checkpointing\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_step = step\n",
    "                if keep_best:\n",
    "                    best_state = deepcopy(model.state_dict())\n",
    "            elif step - best_step > patience:\n",
    "                print(\"early stoping\")\n",
    "                break\n",
    "            # optimizer steping\n",
    "            optimizer.step()\n",
    "            # printing\n",
    "            print(f\"Step {step}: loss = {loss:.3g} metric = {metric:.2%}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"interrupted by user\")\n",
    "    if keep_best:\n",
    "        model.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageClassifier(3, len(labels), [32, 64, 128, 256])\n",
    "model.to(\"cuda:0\")\n",
    "train = batchifyer(*train_data, n_batches=1, batch_size=10000)\n",
    "val = batchifyer(*val_data, n_batches=1, batch_size=10000)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.0E-3)\n",
    "train_loop(model, optimizer, train, val, n_steps=10000, patience=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = arrays_to_tensors(*test_data)\n",
    "y_pred = model.predict(x)\n",
    "acc = accuracy(y_pred, y.to(y_pred.device))\n",
    "print(f\"accuracy {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = test_data\n",
    "f, axes = plt.subplots(figsize=[10, 10], nrows=3, ncols=3)\n",
    "i = 0\n",
    "for axs in axes:\n",
    "    for ax in axs:\n",
    "        ax.imshow(x_test[i].transpose(1, 2, 0))\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(labels[y_pred[i]], color=\"g\" if y_pred[i] == y_test[i] else \"r\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice II\n",
    "\n",
    "Définir et entraîner un modèle de segmentation d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_polygons(image_shape: tuple[int, int], delta: int = 10, n_max_vertices: int = 5):\n",
    "    \"\"\"\n",
    "    generate a set of random polygon parametrized as a list of (x, y) tuples\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_shape : tuple of int\n",
    "        the (height, width) in pixels of the image to fill with polygons\n",
    "    delta : int\n",
    "        the \n",
    "    \"\"\"\n",
    "    assert n_max_vertices >= 3\n",
    "    x_offset, y_offset = np.random.uniform(-delta, delta, 2)  # offset of the polygons grid\n",
    "    x_spacing, y_spacing = np.arange(-delta, image_shape[1]+delta, delta)+x_offset, np.arange(-delta, image_shape[0]+delta, delta)+y_offset\n",
    "    x_centers, y_centers = np.meshgrid(x_spacing, y_spacing, indexing=\"xy\")  # coordinates of polygons centers\n",
    "    Lx, Ly = x_centers.shape\n",
    "    x_centers += np.random.uniform(-delta/2, delta/2, (Lx, Ly))\n",
    "    y_centers += np.random.uniform(-delta/2, delta/2, (Lx, Ly))\n",
    "    thetas = np.cumsum(np.random.uniform(1., 3., (Lx, Ly, n_max_vertices+1)), axis=-1)  # angle of each vertex of each polygon\n",
    "    n_vertices = np.random.randint(3, n_max_vertices+1, (Lx, Ly, 1))  # number of vertices in each polygon\n",
    "    thetas = thetas[..., :-1] * 2*np.pi / np.take_along_axis(thetas, n_vertices, axis=-1)\n",
    "    mu, sigma = delta/2, delta/6\n",
    "    radius = np.clip(np.random.normal(mu, sigma, (Lx, Ly, n_max_vertices)), 0, delta/2)  # radius of each vertex of eahc polygon\n",
    "    return [[(x_center + r*np.cos(theta), y_center + r*np.sin(theta)) for r, theta, _ in zip(points_r, points_theta, range(point_n_vertices))]\n",
    "            for points_r, points_theta, x_center, y_center, point_n_vertices\n",
    "            in zip(radius.reshape(-1, n_max_vertices), thetas.reshape(-1, n_max_vertices), x_centers.reshape(-1), y_centers.reshape(-1), n_vertices.reshape(-1))]\n",
    "\n",
    "def generate_image(width: int = 64, height: int = 64, delta: int = 20):\n",
    "    \"\"\"\n",
    "    generate a an image of a polygon and it's target interior\n",
    "    \"\"\"\n",
    "    shape = (height, width)\n",
    "    img = Image.new(\"L\", shape)\n",
    "    target = Image.new(\"1\", shape)\n",
    "    img_draw = ImageDraw.Draw(img)\n",
    "    target_draw = ImageDraw.Draw(target)\n",
    "    n_polygons = np.random.randint(3, 6)\n",
    "    for polygon in generate_polygons(shape, delta):\n",
    "        img_draw.polygon(polygon, fill=None, outline=\"#ffffff\")\n",
    "        target_draw.polygon(polygon, fill=\"#ffffff\", outline=\"#ffffff\")\n",
    "    return np.array(img, dtype=np.uint8), np.array(target, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_image(64, 64, 20)\n",
    "f, axes = plt.subplots(figsize=[10, 5], ncols=2)\n",
    "for ax, img in zip(axes, [x, y]):\n",
    "    ax.imshow(img, cmap=\"viridis\")\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchesGenerator:\n",
    "    \"\"\"\n",
    "    generate a batch of 'n' (input, target) observations when iterated over\n",
    "    \"\"\"\n",
    "    def __init__(self, n_batches: int, batch_size : int):\n",
    "        self.n_batches = n_batches\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.get_batches()\n",
    "    \n",
    "    def get_batches(self):\n",
    "        for _ in range(self.n_batches):\n",
    "            inputs, targets = (np.stack(arrays, axis=0) for arrays in zip(*[generate_image() for _ in range(self.batch_size)]))\n",
    "            yield torch.tensor(inputs/255., dtype=torch.float32), torch.tensor(targets, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(predicted: torch.Tensor, target: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    returns the F1 score of a binary classification\n",
    "    \"\"\"\n",
    "    assert predicted.shape == target.shape\n",
    "    assert predicted.dtype == torch.bool\n",
    "    assert target.dtype == torch.bool\n",
    "    with torch.no_grad():\n",
    "        tp = torch.sum(predicted & target).detach().cpu().item()\n",
    "        fp = torch.sum(~predicted & target).detach().cpu().item()\n",
    "        fn = torch.sum(predicted & ~target).detach().cpu().item()\n",
    "    return (2*tp) / (2*tp + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSegmenter(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, features: list[int], activation: Callable = torch.relu, kernel_size: tuple[int] = (3, 3), pool: tuple[int, int] = 2):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.ModuleList()\n",
    "        in_features = 1\n",
    "        for out_features in features:\n",
    "            self.encoder.append(Block(in_features, out_features, activation, kernel_size, pool))\n",
    "            in_features = out_features\n",
    "        self.decoder = torch.nn.ModuleList()\n",
    "        for out_features in features[-2::-1] + [1]:\n",
    "            self.decoder.append(Block(in_features+out_features, out_features, activation, kernel_size, (1, 1)))\n",
    "            in_features = out_features\n",
    "        self.output = torch.nn.Conv2d(in_features, 1, (1, 1))\n",
    "    \n",
    "    def forward(self, X: torch.Tensor):\n",
    "        feature_maps = []\n",
    "        X = X.unsqueeze(1).to(self.device)\n",
    "        for stage in self.encoder:\n",
    "            feature_maps.append(X)\n",
    "            X = stage(X)\n",
    "        for stage in self.decoder:\n",
    "            X = F.interpolate(X, scale_factor=2, mode=\"nearest\")\n",
    "            feature_map = feature_maps.pop()\n",
    "            X = torch.cat([X, feature_map], dim=1)\n",
    "            X = stage(X)\n",
    "        self.output(X)\n",
    "        return torch.sigmoid(X).squeeze(1)\n",
    "\n",
    "    def predict(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            Y = self(X)\n",
    "        return Y > 0.5\n",
    "        \n",
    "    def loss(self, X: torch.Tensor, Y: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        y_pred = self(X)\n",
    "        return F.binary_cross_entropy(y_pred, (Y.float() / 255).to(y_pred.device))\n",
    "\n",
    "    def metric(self, X: torch.Tensor, Y: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        return F1_score(y_pred > 0.5, Y.to(y_pred.device))\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return self.output.weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageSegmenter([8, 16, 32])\n",
    "model.to(\"cuda:0\")\n",
    "generator = BatchesGenerator(1, 1000)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.0E-3)\n",
    "train_loop(model, optimizer, generator, generator, n_steps=10000, patience=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(BatchesGenerator(1, 1)))\n",
    "y_pred = model.predict(x)\n",
    "f, axes = plt.subplots(figsize=[15, 5], ncols=3)\n",
    "for ax, img in zip(axes, [x[0], y[0].cpu().numpy(), y_pred[0].cpu().numpy()]):\n",
    "    ax.imshow(img, cmap=\"viridis\")\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2017a09ab1f54c7a6a1af190715fd60264df4a93389a277e03c18d947a6e489"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

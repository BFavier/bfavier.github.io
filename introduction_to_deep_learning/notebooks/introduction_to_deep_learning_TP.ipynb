{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../datasets/CIFAR10/CIFAR-10.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(data))\n",
    "train_idx, val_idx, test_idx = np.split(indices, [int(round(len(indices)*i)) for i in (0.8, 0.9)])\n",
    "train, val, test = data[train_idx], data[val_idx], data[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.imshow(data[np.random.randint(len(data))].transpose(1, 2, 0))\n",
    "ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II - Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, channels: list[int]):\n",
    "        super().__init__()\n",
    "        in_channels = 3\n",
    "        self.linears = torch.nn.ModuleList()\n",
    "        self.activated = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        self.max_pooling = torch.nn.MaxPool2d((2, 2))\n",
    "        self.mean_pooling = torch.nn.AvgPool2d((2, 2))\n",
    "        self.activation = F.relu\n",
    "        kwargs = {\"kernel_size\": (3, 3), \"stride\": (1, 1), \"padding\": (1, 1)}\n",
    "        for out_channels in channels:\n",
    "            self.linears.append(torch.nn.Conv2d(in_channels, out_channels, **kwargs))\n",
    "            self.activated.append(torch.nn.Conv2d(in_channels, out_channels, **kwargs))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm2d(out_channels))\n",
    "            in_channels = out_channels\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for linear, activ, bn in zip(self.linears, self.activated, self.batch_norms):\n",
    "            X = bn(self.max_pooling(self.activation(activ(X))) + self.mean_pooling(linear(X)))\n",
    "        return X\n",
    "        \n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, channels: list[int]):\n",
    "        super().__init__()\n",
    "        in_channels = channels[-1]\n",
    "        print(in_channels, channels[-2::-1]+[3])\n",
    "        self.linears = torch.nn.ModuleList()\n",
    "        self.activated = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        self.activation = F.relu\n",
    "        kwargs = {\"kernel_size\": (3, 3), \"stride\": (1, 1), \"padding\": (1, 1)}\n",
    "        for out_channels in channels[-2::-1]+[3]:\n",
    "            self.linears.append(torch.nn.Conv2d(in_channels, out_channels, **kwargs))\n",
    "            self.activated.append(torch.nn.Conv2d(in_channels, out_channels, **kwargs))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm2d(out_channels))\n",
    "            in_channels = out_channels\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for linear, activ, bn in zip(self.linears, self.activated, self.batch_norms):\n",
    "            X = F.interpolate(X, scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "            X = bn(self.activation(activ(X)) + linear(X))\n",
    "        return X\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, channels: list[int]):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(channels)\n",
    "        self.decoder = Decoder(channels)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.decoder(self.encoder(X))\n",
    "    \n",
    "    def to_tensor(self, array: np.ndarray) -> torch.Tensor:\n",
    "        return torch.tensor(array, dtype=torch.float32, device=self.device) / 255.\n",
    "    \n",
    "    def encode(self, array: np.ndarray) -> np.ndarray:\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.encoder(self.to_tensor(array)).detach().cpu().numpy()\n",
    "    \n",
    "    def decode(self, array: np.ndarray) -> np.ndarray:\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            X = torch.tensor(array, dtype=torch.float32, device=self.device)\n",
    "            return self.decoder(X).detach().cpu().numpy()\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return self.encoder.linears[0].weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(array: np.ndarray, batch_size: int, n_batches: int):\n",
    "    \"\"\"\n",
    "    yield \"n_batches\" batches of size \"batche_size\"\n",
    "    \"\"\"\n",
    "    indices = np.random.permutation(len(array))\n",
    "    for i in range(n_batches):\n",
    "        yield array[indices[i*batch_size:(i+1)*batch_size]]\n",
    "\n",
    "def train_loop(model: Model, optimizer: torch.optim.Optimizer, train_data: np.ndarray, val_data: np.ndarray, n_steps: int = 1000, n_batches: int = 5, batch_size: int = 100):\n",
    "    \"\"\"\n",
    "    train the model for \"n_steps\" steps\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for step in range(n_steps):\n",
    "            optimizer.zero_grad()\n",
    "            # train loss\n",
    "            losses = []\n",
    "            model.train()\n",
    "            for array in batches(train_data, batch_size, n_batches):\n",
    "                X = model.to_tensor(array)\n",
    "                loss = F.mse_loss(model(X), X)\n",
    "                loss.backward()\n",
    "                losses.append(loss.item())\n",
    "            train_loss = sum(losses) / max(1, len(losses))\n",
    "            # val loss\n",
    "            losses = []\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for array in batches(val_data, batch_size, n_batches):\n",
    "                    X = model.to_tensor(array)\n",
    "                    losses.append(F.mse_loss(model(X), X).item())\n",
    "            val_loss = sum(losses) / max(1, len(losses))\n",
    "            # step and display\n",
    "            optimizer.step()\n",
    "            print(f\"Step {step}: train loss = {train_loss:.3g} val loss = {val_loss:.3g}\")\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 [16, 8, 3]\n",
      "Step 0: train loss = 1.33 val loss = 0.307\n",
      "Step 1: train loss = 1.03 val loss = 0.164\n",
      "Step 2: train loss = 0.975 val loss = 0.0948\n",
      "Step 3: train loss = 0.952 val loss = 0.0722\n",
      "Step 4: train loss = 0.937 val loss = 0.077\n",
      "Step 5: train loss = 0.929 val loss = 0.0952\n",
      "Step 6: train loss = 0.927 val loss = 0.109\n",
      "Step 7: train loss = 0.918 val loss = 0.119\n",
      "Step 8: train loss = 0.902 val loss = 0.124\n",
      "Step 9: train loss = 0.897 val loss = 0.129\n",
      "Step 10: train loss = 0.895 val loss = 0.13\n",
      "Step 11: train loss = 0.899 val loss = 0.139\n",
      "Step 12: train loss = 0.89 val loss = 0.152\n",
      "Step 13: train loss = 0.879 val loss = 0.168\n",
      "Step 14: train loss = 0.882 val loss = 0.178\n",
      "Step 15: train loss = 0.881 val loss = 0.209\n",
      "Step 16: train loss = 0.868 val loss = 0.227\n",
      "Step 17: train loss = 0.872 val loss = 0.245\n",
      "Step 18: train loss = 0.861 val loss = 0.281\n",
      "Step 19: train loss = 0.862 val loss = 0.292\n",
      "Step 20: train loss = 0.846 val loss = 0.312\n",
      "Step 21: train loss = 0.857 val loss = 0.337\n",
      "Step 22: train loss = 0.854 val loss = 0.387\n",
      "Step 23: train loss = 0.84 val loss = 0.395\n",
      "Step 24: train loss = 0.849 val loss = 0.405\n",
      "Step 25: train loss = 0.831 val loss = 0.426\n",
      "Step 26: train loss = 0.834 val loss = 0.447\n",
      "Step 27: train loss = 0.83 val loss = 0.462\n",
      "Step 28: train loss = 0.822 val loss = 0.477\n",
      "Step 29: train loss = 0.832 val loss = 0.476\n",
      "Step 30: train loss = 0.819 val loss = 0.513\n",
      "Step 31: train loss = 0.814 val loss = 0.488\n",
      "Step 32: train loss = 0.818 val loss = 0.498\n",
      "Step 33: train loss = 0.822 val loss = 0.525\n",
      "Step 34: train loss = 0.808 val loss = 0.529\n",
      "Step 35: train loss = 0.799 val loss = 0.576\n",
      "Step 36: train loss = 0.794 val loss = 0.585\n",
      "Step 37: train loss = 0.795 val loss = 0.576\n",
      "Step 38: train loss = 0.796 val loss = 0.589\n",
      "Step 39: train loss = 0.791 val loss = 0.571\n",
      "Step 40: train loss = 0.79 val loss = 0.572\n",
      "Step 41: train loss = 0.782 val loss = 0.557\n",
      "Step 42: train loss = 0.788 val loss = 0.544\n",
      "Step 43: train loss = 0.777 val loss = 0.536\n",
      "Step 44: train loss = 0.77 val loss = 0.534\n",
      "Step 45: train loss = 0.775 val loss = 0.511\n",
      "Step 46: train loss = 0.772 val loss = 0.532\n",
      "Step 47: train loss = 0.763 val loss = 0.553\n",
      "Step 48: train loss = 0.768 val loss = 0.561\n",
      "Step 49: train loss = 0.768 val loss = 0.579\n",
      "Step 50: train loss = 0.76 val loss = 0.571\n",
      "Step 51: train loss = 0.763 val loss = 0.593\n",
      "Step 52: train loss = 0.762 val loss = 0.571\n",
      "Step 53: train loss = 0.755 val loss = 0.57\n",
      "Step 54: train loss = 0.743 val loss = 0.562\n",
      "Step 55: train loss = 0.75 val loss = 0.566\n",
      "Step 56: train loss = 0.746 val loss = 0.559\n",
      "Step 57: train loss = 0.745 val loss = 0.584\n",
      "Step 58: train loss = 0.739 val loss = 0.609\n",
      "Step 59: train loss = 0.734 val loss = 0.614\n",
      "Step 60: train loss = 0.731 val loss = 0.624\n",
      "Step 61: train loss = 0.729 val loss = 0.612\n",
      "Step 62: train loss = 0.73 val loss = 0.578\n",
      "Step 63: train loss = 0.728 val loss = 0.602\n",
      "Step 64: train loss = 0.727 val loss = 0.557\n",
      "Step 65: train loss = 0.726 val loss = 0.557\n",
      "Step 66: train loss = 0.726 val loss = 0.566\n",
      "Step 67: train loss = 0.718 val loss = 0.551\n",
      "Step 68: train loss = 0.716 val loss = 0.592\n",
      "Step 69: train loss = 0.72 val loss = 0.631\n",
      "Step 70: train loss = 0.714 val loss = 0.633\n",
      "Step 71: train loss = 0.709 val loss = 0.61\n",
      "Step 72: train loss = 0.712 val loss = 0.559\n",
      "Step 73: train loss = 0.702 val loss = 0.561\n",
      "Step 74: train loss = 0.697 val loss = 0.547\n",
      "Step 75: train loss = 0.699 val loss = 0.552\n",
      "Step 76: train loss = 0.701 val loss = 0.571\n",
      "Step 77: train loss = 0.693 val loss = 0.572\n",
      "Step 78: train loss = 0.688 val loss = 0.594\n",
      "Step 79: train loss = 0.684 val loss = 0.576\n",
      "Step 80: train loss = 0.685 val loss = 0.595\n",
      "Step 81: train loss = 0.689 val loss = 0.597\n",
      "Step 82: train loss = 0.683 val loss = 0.54\n",
      "Step 83: train loss = 0.687 val loss = 0.555\n",
      "Step 84: train loss = 0.683 val loss = 0.529\n",
      "Step 85: train loss = 0.67 val loss = 0.546\n",
      "Step 86: train loss = 0.676 val loss = 0.574\n",
      "Step 87: train loss = 0.673 val loss = 0.548\n",
      "Step 88: train loss = 0.668 val loss = 0.547\n",
      "Step 89: train loss = 0.668 val loss = 0.573\n",
      "Step 90: train loss = 0.67 val loss = 0.552\n",
      "Step 91: train loss = 0.664 val loss = 0.55\n",
      "Step 92: train loss = 0.665 val loss = 0.537\n",
      "Step 93: train loss = 0.66 val loss = 0.537\n",
      "Step 94: train loss = 0.657 val loss = 0.565\n",
      "Step 95: train loss = 0.652 val loss = 0.566\n",
      "Step 96: train loss = 0.653 val loss = 0.571\n",
      "Step 97: train loss = 0.646 val loss = 0.547\n",
      "Step 98: train loss = 0.647 val loss = 0.557\n",
      "Step 99: train loss = 0.642 val loss = 0.551\n",
      "Step 100: train loss = 0.641 val loss = 0.563\n",
      "Step 101: train loss = 0.639 val loss = 0.57\n",
      "Step 102: train loss = 0.639 val loss = 0.585\n",
      "Step 103: train loss = 0.639 val loss = 0.561\n",
      "Step 104: train loss = 0.634 val loss = 0.552\n",
      "Step 105: train loss = 0.63 val loss = 0.56\n",
      "Step 106: train loss = 0.633 val loss = 0.566\n",
      "Step 107: train loss = 0.626 val loss = 0.57\n",
      "Step 108: train loss = 0.622 val loss = 0.564\n",
      "Step 109: train loss = 0.623 val loss = 0.58\n",
      "Step 110: train loss = 0.626 val loss = 0.575\n",
      "Step 111: train loss = 0.616 val loss = 0.579\n",
      "Step 112: train loss = 0.619 val loss = 0.555\n",
      "Step 113: train loss = 0.615 val loss = 0.567\n",
      "Step 114: train loss = 0.611 val loss = 0.562\n",
      "Step 115: train loss = 0.614 val loss = 0.577\n",
      "Step 116: train loss = 0.607 val loss = 0.559\n",
      "Step 117: train loss = 0.607 val loss = 0.543\n",
      "Step 118: train loss = 0.606 val loss = 0.561\n",
      "Step 119: train loss = 0.607 val loss = 0.56\n",
      "Step 120: train loss = 0.601 val loss = 0.567\n",
      "Step 121: train loss = 0.594 val loss = 0.57\n",
      "Step 122: train loss = 0.593 val loss = 0.557\n",
      "Step 123: train loss = 0.591 val loss = 0.567\n",
      "Step 124: train loss = 0.596 val loss = 0.576\n",
      "Step 125: train loss = 0.588 val loss = 0.555\n",
      "Step 126: train loss = 0.587 val loss = 0.555\n",
      "Step 127: train loss = 0.585 val loss = 0.577\n",
      "Step 128: train loss = 0.582 val loss = 0.532\n",
      "Step 129: train loss = 0.576 val loss = 0.536\n",
      "Step 130: train loss = 0.583 val loss = 0.544\n",
      "Step 131: train loss = 0.575 val loss = 0.544\n",
      "Step 132: train loss = 0.574 val loss = 0.537\n",
      "Step 133: train loss = 0.581 val loss = 0.53\n",
      "Step 134: train loss = 0.573 val loss = 0.508\n",
      "Step 135: train loss = 0.57 val loss = 0.514\n",
      "Step 136: train loss = 0.566 val loss = 0.522\n",
      "Step 137: train loss = 0.564 val loss = 0.55\n",
      "Step 138: train loss = 0.564 val loss = 0.557\n",
      "Step 139: train loss = 0.561 val loss = 0.531\n",
      "Step 140: train loss = 0.564 val loss = 0.518\n",
      "Step 141: train loss = 0.557 val loss = 0.53\n",
      "Step 142: train loss = 0.556 val loss = 0.503\n",
      "Step 143: train loss = 0.55 val loss = 0.521\n",
      "Step 144: train loss = 0.553 val loss = 0.552\n",
      "Step 145: train loss = 0.556 val loss = 0.539\n",
      "Step 146: train loss = 0.553 val loss = 0.49\n",
      "Step 147: train loss = 0.546 val loss = 0.496\n",
      "Step 148: train loss = 0.542 val loss = 0.512\n",
      "Step 149: train loss = 0.546 val loss = 0.524\n",
      "Step 150: train loss = 0.538 val loss = 0.537\n",
      "Step 151: train loss = 0.542 val loss = 0.485\n",
      "Step 152: train loss = 0.541 val loss = 0.519\n",
      "Step 153: train loss = 0.537 val loss = 0.532\n",
      "Step 154: train loss = 0.531 val loss = 0.524\n",
      "Step 155: train loss = 0.533 val loss = 0.518\n",
      "Step 156: train loss = 0.534 val loss = 0.513\n",
      "Step 157: train loss = 0.533 val loss = 0.533\n",
      "Step 158: train loss = 0.525 val loss = 0.528\n",
      "Step 159: train loss = 0.522 val loss = 0.491\n",
      "Step 160: train loss = 0.525 val loss = 0.498\n",
      "Step 161: train loss = 0.522 val loss = 0.538\n",
      "Step 162: train loss = 0.516 val loss = 0.522\n",
      "Step 163: train loss = 0.519 val loss = 0.504\n",
      "Step 164: train loss = 0.52 val loss = 0.494\n",
      "Step 165: train loss = 0.518 val loss = 0.511\n",
      "Step 166: train loss = 0.507 val loss = 0.525\n",
      "Step 167: train loss = 0.509 val loss = 0.5\n",
      "Step 168: train loss = 0.508 val loss = 0.473\n",
      "Step 169: train loss = 0.51 val loss = 0.458\n",
      "Step 170: train loss = 0.508 val loss = 0.48\n",
      "Step 171: train loss = 0.508 val loss = 0.51\n",
      "Step 172: train loss = 0.503 val loss = 0.479\n",
      "Step 173: train loss = 0.495 val loss = 0.472\n",
      "Step 174: train loss = 0.499 val loss = 0.498\n",
      "Step 175: train loss = 0.498 val loss = 0.514\n",
      "Step 176: train loss = 0.488 val loss = 0.454\n",
      "Step 177: train loss = 0.496 val loss = 0.453\n",
      "Step 178: train loss = 0.49 val loss = 0.484\n",
      "Step 179: train loss = 0.491 val loss = 0.495\n",
      "Step 180: train loss = 0.491 val loss = 0.47\n",
      "Step 181: train loss = 0.486 val loss = 0.446\n",
      "Step 182: train loss = 0.486 val loss = 0.488\n",
      "Step 183: train loss = 0.482 val loss = 0.496\n",
      "Step 184: train loss = 0.479 val loss = 0.48\n",
      "Step 185: train loss = 0.484 val loss = 0.455\n",
      "Step 186: train loss = 0.48 val loss = 0.454\n",
      "Step 187: train loss = 0.474 val loss = 0.479\n",
      "Step 188: train loss = 0.474 val loss = 0.459\n",
      "Step 189: train loss = 0.477 val loss = 0.437\n",
      "Step 190: train loss = 0.471 val loss = 0.457\n",
      "Step 191: train loss = 0.468 val loss = 0.468\n",
      "Step 192: train loss = 0.472 val loss = 0.444\n",
      "Step 193: train loss = 0.466 val loss = 0.436\n",
      "Step 194: train loss = 0.466 val loss = 0.434\n",
      "Step 195: train loss = 0.464 val loss = 0.473\n",
      "Step 196: train loss = 0.467 val loss = 0.488\n",
      "Step 197: train loss = 0.46 val loss = 0.429\n",
      "Step 198: train loss = 0.458 val loss = 0.412\n",
      "Step 199: train loss = 0.454 val loss = 0.439\n",
      "Step 200: train loss = 0.453 val loss = 0.47\n",
      "Step 201: train loss = 0.451 val loss = 0.445\n",
      "Step 202: train loss = 0.452 val loss = 0.409\n",
      "Step 203: train loss = 0.448 val loss = 0.406\n",
      "Step 204: train loss = 0.447 val loss = 0.442\n",
      "Step 205: train loss = 0.449 val loss = 0.456\n",
      "Step 206: train loss = 0.447 val loss = 0.428\n",
      "Step 207: train loss = 0.444 val loss = 0.415\n",
      "Step 208: train loss = 0.447 val loss = 0.437\n",
      "Step 209: train loss = 0.446 val loss = 0.427\n",
      "Step 210: train loss = 0.438 val loss = 0.412\n",
      "Step 211: train loss = 0.445 val loss = 0.393\n",
      "Step 212: train loss = 0.433 val loss = 0.425\n",
      "Step 213: train loss = 0.435 val loss = 0.435\n",
      "Step 214: train loss = 0.43 val loss = 0.416\n",
      "Step 215: train loss = 0.439 val loss = 0.396\n",
      "Step 216: train loss = 0.434 val loss = 0.412\n",
      "Step 217: train loss = 0.432 val loss = 0.411\n",
      "Step 218: train loss = 0.433 val loss = 0.421\n",
      "Step 219: train loss = 0.43 val loss = 0.412\n",
      "Step 220: train loss = 0.428 val loss = 0.407\n",
      "Step 221: train loss = 0.423 val loss = 0.42\n",
      "Step 222: train loss = 0.428 val loss = 0.414\n",
      "Step 223: train loss = 0.423 val loss = 0.4\n",
      "Step 224: train loss = 0.424 val loss = 0.391\n",
      "Step 225: train loss = 0.416 val loss = 0.423\n",
      "Step 226: train loss = 0.411 val loss = 0.423\n",
      "Step 227: train loss = 0.415 val loss = 0.409\n",
      "Step 228: train loss = 0.416 val loss = 0.387\n",
      "Step 229: train loss = 0.411 val loss = 0.408\n",
      "Step 230: train loss = 0.413 val loss = 0.41\n",
      "Step 231: train loss = 0.406 val loss = 0.402\n",
      "Step 232: train loss = 0.414 val loss = 0.4\n",
      "Step 233: train loss = 0.406 val loss = 0.379\n",
      "Step 234: train loss = 0.411 val loss = 0.395\n",
      "Step 235: train loss = 0.4 val loss = 0.403\n",
      "Step 236: train loss = 0.403 val loss = 0.395\n",
      "Step 237: train loss = 0.4 val loss = 0.38\n",
      "Step 238: train loss = 0.398 val loss = 0.38\n",
      "Step 239: train loss = 0.396 val loss = 0.391\n",
      "Step 240: train loss = 0.397 val loss = 0.368\n",
      "Step 241: train loss = 0.39 val loss = 0.368\n",
      "Step 242: train loss = 0.392 val loss = 0.388\n",
      "Step 243: train loss = 0.397 val loss = 0.399\n",
      "Step 244: train loss = 0.391 val loss = 0.379\n",
      "Step 245: train loss = 0.385 val loss = 0.354\n",
      "Step 246: train loss = 0.389 val loss = 0.381\n",
      "Step 247: train loss = 0.388 val loss = 0.408\n",
      "Step 248: train loss = 0.389 val loss = 0.385\n",
      "Step 249: train loss = 0.385 val loss = 0.338\n",
      "Step 250: train loss = 0.384 val loss = 0.354\n",
      "Step 251: train loss = 0.381 val loss = 0.39\n",
      "Step 252: train loss = 0.379 val loss = 0.369\n",
      "Step 253: train loss = 0.38 val loss = 0.355\n",
      "Step 254: train loss = 0.378 val loss = 0.351\n",
      "Step 255: train loss = 0.377 val loss = 0.36\n",
      "Step 256: train loss = 0.376 val loss = 0.376\n",
      "Step 257: train loss = 0.374 val loss = 0.37\n",
      "Step 258: train loss = 0.374 val loss = 0.347\n",
      "Step 259: train loss = 0.373 val loss = 0.354\n",
      "Step 260: train loss = 0.372 val loss = 0.344\n",
      "Step 261: train loss = 0.369 val loss = 0.345\n",
      "Step 262: train loss = 0.367 val loss = 0.344\n",
      "Step 263: train loss = 0.367 val loss = 0.371\n",
      "Step 264: train loss = 0.369 val loss = 0.362\n",
      "Step 265: train loss = 0.364 val loss = 0.35\n",
      "Step 266: train loss = 0.363 val loss = 0.341\n",
      "Step 267: train loss = 0.366 val loss = 0.351\n",
      "Step 268: train loss = 0.363 val loss = 0.364\n",
      "Step 269: train loss = 0.361 val loss = 0.341\n",
      "Step 270: train loss = 0.358 val loss = 0.332\n",
      "Step 271: train loss = 0.358 val loss = 0.348\n",
      "Step 272: train loss = 0.358 val loss = 0.362\n",
      "Step 273: train loss = 0.354 val loss = 0.349\n",
      "Step 274: train loss = 0.351 val loss = 0.341\n",
      "Step 275: train loss = 0.348 val loss = 0.338\n",
      "Step 276: train loss = 0.348 val loss = 0.352\n",
      "Step 277: train loss = 0.348 val loss = 0.338\n",
      "Step 278: train loss = 0.35 val loss = 0.334\n",
      "Step 279: train loss = 0.347 val loss = 0.34\n",
      "Step 280: train loss = 0.346 val loss = 0.331\n",
      "Step 281: train loss = 0.349 val loss = 0.34\n",
      "Step 282: train loss = 0.343 val loss = 0.333\n",
      "Step 283: train loss = 0.344 val loss = 0.312\n",
      "Step 284: train loss = 0.342 val loss = 0.329\n",
      "Step 285: train loss = 0.339 val loss = 0.341\n",
      "Step 286: train loss = 0.343 val loss = 0.342\n",
      "Step 287: train loss = 0.338 val loss = 0.343\n",
      "Step 288: train loss = 0.339 val loss = 0.346\n",
      "Step 289: train loss = 0.333 val loss = 0.337\n",
      "Step 290: train loss = 0.331 val loss = 0.329\n",
      "Step 291: train loss = 0.33 val loss = 0.326\n",
      "Step 292: train loss = 0.332 val loss = 0.328\n",
      "Step 293: train loss = 0.329 val loss = 0.314\n",
      "Step 294: train loss = 0.331 val loss = 0.329\n",
      "Step 295: train loss = 0.327 val loss = 0.327\n",
      "Step 296: train loss = 0.329 val loss = 0.315\n",
      "Step 297: train loss = 0.326 val loss = 0.312\n",
      "Step 298: train loss = 0.323 val loss = 0.329\n",
      "Step 299: train loss = 0.32 val loss = 0.328\n",
      "Step 300: train loss = 0.324 val loss = 0.322\n",
      "Step 301: train loss = 0.32 val loss = 0.303\n",
      "Step 302: train loss = 0.32 val loss = 0.325\n",
      "Step 303: train loss = 0.317 val loss = 0.317\n",
      "Step 304: train loss = 0.317 val loss = 0.306\n",
      "Step 305: train loss = 0.316 val loss = 0.301\n",
      "Step 306: train loss = 0.314 val loss = 0.315\n",
      "Step 307: train loss = 0.315 val loss = 0.327\n",
      "Step 308: train loss = 0.316 val loss = 0.312\n",
      "Step 309: train loss = 0.315 val loss = 0.306\n",
      "Step 310: train loss = 0.313 val loss = 0.302\n",
      "Step 311: train loss = 0.31 val loss = 0.293\n",
      "Step 312: train loss = 0.31 val loss = 0.294\n",
      "Step 313: train loss = 0.306 val loss = 0.317\n",
      "Step 314: train loss = 0.303 val loss = 0.314\n",
      "Step 315: train loss = 0.303 val loss = 0.299\n",
      "Step 316: train loss = 0.301 val loss = 0.301\n",
      "Step 317: train loss = 0.299 val loss = 0.3\n",
      "Step 318: train loss = 0.3 val loss = 0.309\n",
      "Step 319: train loss = 0.303 val loss = 0.282\n",
      "Step 320: train loss = 0.297 val loss = 0.284\n",
      "Step 321: train loss = 0.298 val loss = 0.3\n",
      "Step 322: train loss = 0.294 val loss = 0.3\n",
      "Step 323: train loss = 0.295 val loss = 0.297\n",
      "Step 324: train loss = 0.296 val loss = 0.298\n",
      "Step 325: train loss = 0.294 val loss = 0.3\n",
      "Step 326: train loss = 0.297 val loss = 0.273\n",
      "Step 327: train loss = 0.296 val loss = 0.28\n",
      "Step 328: train loss = 0.288 val loss = 0.281\n",
      "Step 329: train loss = 0.291 val loss = 0.286\n",
      "Step 330: train loss = 0.291 val loss = 0.278\n",
      "Step 331: train loss = 0.288 val loss = 0.279\n",
      "Step 332: train loss = 0.29 val loss = 0.29\n",
      "Step 333: train loss = 0.286 val loss = 0.293\n",
      "Step 334: train loss = 0.287 val loss = 0.282\n",
      "Step 335: train loss = 0.284 val loss = 0.268\n",
      "Step 336: train loss = 0.282 val loss = 0.28\n",
      "Step 337: train loss = 0.282 val loss = 0.289\n",
      "Step 338: train loss = 0.28 val loss = 0.286\n",
      "Step 339: train loss = 0.282 val loss = 0.282\n",
      "Step 340: train loss = 0.278 val loss = 0.277\n",
      "Step 341: train loss = 0.276 val loss = 0.273\n",
      "Step 342: train loss = 0.276 val loss = 0.266\n",
      "Step 343: train loss = 0.275 val loss = 0.268\n",
      "Step 344: train loss = 0.275 val loss = 0.278\n",
      "Step 345: train loss = 0.272 val loss = 0.279\n",
      "Step 346: train loss = 0.276 val loss = 0.269\n",
      "Step 347: train loss = 0.272 val loss = 0.258\n",
      "Step 348: train loss = 0.27 val loss = 0.283\n",
      "Step 349: train loss = 0.267 val loss = 0.282\n",
      "Step 350: train loss = 0.272 val loss = 0.265\n",
      "Step 351: train loss = 0.269 val loss = 0.245\n",
      "Step 352: train loss = 0.27 val loss = 0.266\n",
      "Step 353: train loss = 0.269 val loss = 0.265\n",
      "Step 354: train loss = 0.263 val loss = 0.245\n",
      "Step 355: train loss = 0.265 val loss = 0.245\n",
      "Step 356: train loss = 0.258 val loss = 0.257\n",
      "Step 357: train loss = 0.263 val loss = 0.284\n",
      "Step 358: train loss = 0.263 val loss = 0.268\n",
      "Step 359: train loss = 0.26 val loss = 0.245\n",
      "Step 360: train loss = 0.258 val loss = 0.25\n",
      "Step 361: train loss = 0.261 val loss = 0.261\n",
      "Step 362: train loss = 0.256 val loss = 0.252\n",
      "Step 363: train loss = 0.257 val loss = 0.239\n",
      "Step 364: train loss = 0.255 val loss = 0.25\n",
      "Step 365: train loss = 0.255 val loss = 0.253\n",
      "Step 366: train loss = 0.254 val loss = 0.249\n",
      "Step 367: train loss = 0.252 val loss = 0.243\n",
      "Step 368: train loss = 0.254 val loss = 0.236\n",
      "Step 369: train loss = 0.252 val loss = 0.241\n",
      "Step 370: train loss = 0.25 val loss = 0.237\n",
      "Step 371: train loss = 0.249 val loss = 0.239\n",
      "Step 372: train loss = 0.248 val loss = 0.237\n",
      "Step 373: train loss = 0.246 val loss = 0.238\n",
      "Step 374: train loss = 0.247 val loss = 0.235\n",
      "Step 375: train loss = 0.249 val loss = 0.243\n",
      "Step 376: train loss = 0.244 val loss = 0.239\n",
      "Step 377: train loss = 0.243 val loss = 0.232\n",
      "Step 378: train loss = 0.241 val loss = 0.241\n",
      "Step 379: train loss = 0.244 val loss = 0.249\n",
      "Step 380: train loss = 0.237 val loss = 0.236\n",
      "Step 381: train loss = 0.242 val loss = 0.227\n",
      "Step 382: train loss = 0.239 val loss = 0.243\n",
      "Step 383: train loss = 0.239 val loss = 0.246\n",
      "Step 384: train loss = 0.24 val loss = 0.236\n",
      "Step 385: train loss = 0.236 val loss = 0.225\n",
      "Step 386: train loss = 0.237 val loss = 0.24\n",
      "Step 387: train loss = 0.237 val loss = 0.238\n",
      "Step 388: train loss = 0.237 val loss = 0.234\n",
      "Step 389: train loss = 0.237 val loss = 0.23\n",
      "Step 390: train loss = 0.228 val loss = 0.228\n",
      "Step 391: train loss = 0.234 val loss = 0.247\n",
      "Step 392: train loss = 0.23 val loss = 0.219\n",
      "Step 393: train loss = 0.231 val loss = 0.223\n",
      "Step 394: train loss = 0.226 val loss = 0.224\n",
      "Step 395: train loss = 0.23 val loss = 0.243\n",
      "Step 396: train loss = 0.226 val loss = 0.234\n",
      "Step 397: train loss = 0.23 val loss = 0.223\n",
      "Step 398: train loss = 0.224 val loss = 0.21\n",
      "Step 399: train loss = 0.223 val loss = 0.232\n",
      "Step 400: train loss = 0.225 val loss = 0.233\n",
      "Step 401: train loss = 0.224 val loss = 0.223\n",
      "Step 402: train loss = 0.221 val loss = 0.212\n",
      "Step 403: train loss = 0.223 val loss = 0.23\n",
      "Step 404: train loss = 0.224 val loss = 0.222\n",
      "Step 405: train loss = 0.218 val loss = 0.202\n",
      "Step 406: train loss = 0.221 val loss = 0.215\n",
      "Step 407: train loss = 0.219 val loss = 0.225\n",
      "Step 408: train loss = 0.218 val loss = 0.211\n",
      "Step 409: train loss = 0.22 val loss = 0.208\n",
      "Step 410: train loss = 0.22 val loss = 0.207\n",
      "Step 411: train loss = 0.218 val loss = 0.223\n",
      "Step 412: train loss = 0.216 val loss = 0.22\n",
      "Step 413: train loss = 0.213 val loss = 0.212\n",
      "Step 414: train loss = 0.21 val loss = 0.207\n",
      "Step 415: train loss = 0.213 val loss = 0.227\n",
      "Step 416: train loss = 0.21 val loss = 0.227\n",
      "Step 417: train loss = 0.21 val loss = 0.203\n",
      "Step 418: train loss = 0.212 val loss = 0.201\n",
      "Step 419: train loss = 0.207 val loss = 0.208\n",
      "Step 420: train loss = 0.21 val loss = 0.214\n",
      "Step 421: train loss = 0.206 val loss = 0.205\n",
      "Step 422: train loss = 0.212 val loss = 0.197\n",
      "Step 423: train loss = 0.204 val loss = 0.2\n",
      "Step 424: train loss = 0.207 val loss = 0.205\n",
      "Step 425: train loss = 0.203 val loss = 0.208\n",
      "Step 426: train loss = 0.202 val loss = 0.208\n",
      "Step 427: train loss = 0.203 val loss = 0.205\n",
      "Step 428: train loss = 0.204 val loss = 0.197\n",
      "Step 429: train loss = 0.201 val loss = 0.197\n",
      "Step 430: train loss = 0.201 val loss = 0.193\n",
      "Step 431: train loss = 0.2 val loss = 0.2\n",
      "Step 432: train loss = 0.201 val loss = 0.202\n",
      "Step 433: train loss = 0.195 val loss = 0.19\n",
      "Step 434: train loss = 0.2 val loss = 0.197\n",
      "Step 435: train loss = 0.197 val loss = 0.19\n",
      "Step 436: train loss = 0.199 val loss = 0.201\n",
      "Step 437: train loss = 0.194 val loss = 0.194\n",
      "Step 438: train loss = 0.193 val loss = 0.191\n",
      "Step 439: train loss = 0.195 val loss = 0.195\n",
      "Step 440: train loss = 0.195 val loss = 0.202\n",
      "Step 441: train loss = 0.192 val loss = 0.199\n",
      "Step 442: train loss = 0.192 val loss = 0.196\n",
      "Step 443: train loss = 0.196 val loss = 0.192\n",
      "Step 444: train loss = 0.189 val loss = 0.18\n",
      "Step 445: train loss = 0.189 val loss = 0.188\n",
      "Step 446: train loss = 0.189 val loss = 0.182\n",
      "Step 447: train loss = 0.194 val loss = 0.18\n",
      "Step 448: train loss = 0.189 val loss = 0.179\n",
      "Step 449: train loss = 0.188 val loss = 0.188\n",
      "Step 450: train loss = 0.187 val loss = 0.19\n",
      "Step 451: train loss = 0.185 val loss = 0.185\n",
      "Step 452: train loss = 0.184 val loss = 0.179\n",
      "Step 453: train loss = 0.185 val loss = 0.191\n",
      "Step 454: train loss = 0.181 val loss = 0.183\n",
      "Step 455: train loss = 0.184 val loss = 0.18\n",
      "Step 456: train loss = 0.182 val loss = 0.179\n",
      "Step 457: train loss = 0.184 val loss = 0.183\n",
      "Step 458: train loss = 0.181 val loss = 0.182\n",
      "Step 459: train loss = 0.18 val loss = 0.179\n",
      "Step 460: train loss = 0.178 val loss = 0.169\n",
      "Step 461: train loss = 0.181 val loss = 0.178\n",
      "Step 462: train loss = 0.179 val loss = 0.182\n",
      "Step 463: train loss = 0.176 val loss = 0.172\n",
      "Step 464: train loss = 0.177 val loss = 0.173\n",
      "Step 465: train loss = 0.178 val loss = 0.178\n",
      "Step 466: train loss = 0.176 val loss = 0.176\n",
      "Step 467: train loss = 0.177 val loss = 0.178\n",
      "Step 468: train loss = 0.175 val loss = 0.166\n",
      "Step 469: train loss = 0.171 val loss = 0.165\n",
      "Step 470: train loss = 0.174 val loss = 0.179\n",
      "Step 471: train loss = 0.176 val loss = 0.172\n",
      "Step 472: train loss = 0.173 val loss = 0.167\n",
      "Step 473: train loss = 0.168 val loss = 0.175\n",
      "Step 474: train loss = 0.166 val loss = 0.18\n",
      "Step 475: train loss = 0.171 val loss = 0.178\n",
      "Step 476: train loss = 0.17 val loss = 0.164\n",
      "Step 477: train loss = 0.172 val loss = 0.164\n",
      "Step 478: train loss = 0.169 val loss = 0.165\n",
      "Step 479: train loss = 0.169 val loss = 0.164\n",
      "Step 480: train loss = 0.167 val loss = 0.165\n",
      "Step 481: train loss = 0.167 val loss = 0.166\n",
      "Step 482: train loss = 0.166 val loss = 0.168\n",
      "Step 483: train loss = 0.164 val loss = 0.165\n",
      "Step 484: train loss = 0.162 val loss = 0.156\n",
      "Step 485: train loss = 0.163 val loss = 0.169\n",
      "Step 486: train loss = 0.165 val loss = 0.167\n",
      "Step 487: train loss = 0.161 val loss = 0.16\n",
      "Step 488: train loss = 0.161 val loss = 0.153\n",
      "Step 489: train loss = 0.162 val loss = 0.156\n",
      "Step 490: train loss = 0.158 val loss = 0.161\n",
      "Step 491: train loss = 0.16 val loss = 0.16\n",
      "Step 492: train loss = 0.161 val loss = 0.157\n",
      "Step 493: train loss = 0.159 val loss = 0.157\n",
      "Step 494: train loss = 0.157 val loss = 0.16\n",
      "Step 495: train loss = 0.159 val loss = 0.153\n",
      "Step 496: train loss = 0.157 val loss = 0.155\n",
      "Step 497: train loss = 0.159 val loss = 0.161\n",
      "Step 498: train loss = 0.154 val loss = 0.154\n",
      "Step 499: train loss = 0.156 val loss = 0.156\n",
      "Step 500: train loss = 0.153 val loss = 0.155\n",
      "Step 501: train loss = 0.156 val loss = 0.159\n",
      "Step 502: train loss = 0.156 val loss = 0.152\n",
      "Step 503: train loss = 0.152 val loss = 0.143\n",
      "Step 504: train loss = 0.152 val loss = 0.145\n",
      "Step 505: train loss = 0.154 val loss = 0.153\n",
      "Step 506: train loss = 0.152 val loss = 0.15\n",
      "Step 507: train loss = 0.149 val loss = 0.144\n",
      "Step 508: train loss = 0.149 val loss = 0.149\n",
      "Step 509: train loss = 0.15 val loss = 0.149\n",
      "Step 510: train loss = 0.149 val loss = 0.146\n",
      "Step 511: train loss = 0.149 val loss = 0.144\n",
      "Step 512: train loss = 0.149 val loss = 0.145\n",
      "Step 513: train loss = 0.147 val loss = 0.142\n",
      "Step 514: train loss = 0.148 val loss = 0.143\n",
      "Step 515: train loss = 0.144 val loss = 0.144\n",
      "Step 516: train loss = 0.145 val loss = 0.145\n",
      "Step 517: train loss = 0.146 val loss = 0.145\n",
      "Step 518: train loss = 0.146 val loss = 0.144\n",
      "Step 519: train loss = 0.142 val loss = 0.138\n",
      "Step 520: train loss = 0.148 val loss = 0.147\n",
      "Step 521: train loss = 0.143 val loss = 0.138\n",
      "Step 522: train loss = 0.143 val loss = 0.135\n",
      "Step 523: train loss = 0.141 val loss = 0.141\n",
      "Step 524: train loss = 0.142 val loss = 0.141\n",
      "Step 525: train loss = 0.141 val loss = 0.14\n",
      "Step 526: train loss = 0.141 val loss = 0.136\n",
      "Step 527: train loss = 0.141 val loss = 0.137\n",
      "Step 528: train loss = 0.139 val loss = 0.139\n",
      "Step 529: train loss = 0.138 val loss = 0.136\n",
      "Step 530: train loss = 0.14 val loss = 0.134\n",
      "Step 531: train loss = 0.138 val loss = 0.13\n",
      "Step 532: train loss = 0.136 val loss = 0.128\n",
      "Step 533: train loss = 0.136 val loss = 0.141\n",
      "Step 534: train loss = 0.137 val loss = 0.139\n",
      "Step 535: train loss = 0.134 val loss = 0.132\n",
      "Step 536: train loss = 0.139 val loss = 0.137\n",
      "Step 537: train loss = 0.135 val loss = 0.128\n",
      "Step 538: train loss = 0.136 val loss = 0.13\n",
      "Step 539: train loss = 0.136 val loss = 0.135\n",
      "Step 540: train loss = 0.133 val loss = 0.134\n",
      "Step 541: train loss = 0.134 val loss = 0.134\n",
      "Step 542: train loss = 0.136 val loss = 0.133\n",
      "Step 543: train loss = 0.131 val loss = 0.131\n",
      "Step 544: train loss = 0.128 val loss = 0.125\n",
      "Step 545: train loss = 0.132 val loss = 0.135\n",
      "Step 546: train loss = 0.131 val loss = 0.129\n",
      "Step 547: train loss = 0.13 val loss = 0.128\n",
      "Step 548: train loss = 0.132 val loss = 0.125\n",
      "Step 549: train loss = 0.13 val loss = 0.131\n",
      "Step 550: train loss = 0.129 val loss = 0.125\n",
      "Step 551: train loss = 0.128 val loss = 0.123\n",
      "Step 552: train loss = 0.129 val loss = 0.125\n",
      "Step 553: train loss = 0.128 val loss = 0.128\n",
      "Step 554: train loss = 0.127 val loss = 0.125\n",
      "Step 555: train loss = 0.125 val loss = 0.129\n",
      "Step 556: train loss = 0.122 val loss = 0.123\n",
      "Step 557: train loss = 0.124 val loss = 0.127\n",
      "Step 558: train loss = 0.125 val loss = 0.125\n",
      "Step 559: train loss = 0.123 val loss = 0.115\n",
      "Step 560: train loss = 0.122 val loss = 0.121\n",
      "Step 561: train loss = 0.123 val loss = 0.126\n",
      "Step 562: train loss = 0.119 val loss = 0.121\n",
      "Step 563: train loss = 0.122 val loss = 0.121\n",
      "Step 564: train loss = 0.122 val loss = 0.116\n",
      "Step 565: train loss = 0.12 val loss = 0.111\n",
      "Step 566: train loss = 0.12 val loss = 0.117\n",
      "Step 567: train loss = 0.12 val loss = 0.119\n",
      "Step 568: train loss = 0.121 val loss = 0.117\n",
      "Step 569: train loss = 0.119 val loss = 0.116\n",
      "Step 570: train loss = 0.122 val loss = 0.111\n",
      "Step 571: train loss = 0.118 val loss = 0.118\n",
      "Step 572: train loss = 0.117 val loss = 0.119\n",
      "Step 573: train loss = 0.119 val loss = 0.117\n",
      "Step 574: train loss = 0.117 val loss = 0.111\n",
      "Step 575: train loss = 0.115 val loss = 0.113\n",
      "Step 576: train loss = 0.117 val loss = 0.112\n",
      "Step 577: train loss = 0.116 val loss = 0.113\n",
      "Step 578: train loss = 0.115 val loss = 0.115\n",
      "Step 579: train loss = 0.117 val loss = 0.115\n",
      "Step 580: train loss = 0.116 val loss = 0.107\n",
      "Step 581: train loss = 0.114 val loss = 0.103\n",
      "Step 582: train loss = 0.116 val loss = 0.112\n",
      "Step 583: train loss = 0.115 val loss = 0.112\n",
      "Step 584: train loss = 0.114 val loss = 0.109\n",
      "Step 585: train loss = 0.113 val loss = 0.108\n",
      "Step 586: train loss = 0.114 val loss = 0.106\n",
      "Step 587: train loss = 0.111 val loss = 0.113\n",
      "Step 588: train loss = 0.111 val loss = 0.123\n",
      "Step 589: train loss = 0.111 val loss = 0.113\n",
      "Step 590: train loss = 0.11 val loss = 0.103\n",
      "Step 591: train loss = 0.109 val loss = 0.109\n",
      "Step 592: train loss = 0.11 val loss = 0.111\n",
      "Step 593: train loss = 0.109 val loss = 0.108\n",
      "Step 594: train loss = 0.113 val loss = 0.107\n",
      "Step 595: train loss = 0.106 val loss = 0.105\n",
      "Step 596: train loss = 0.107 val loss = 0.118\n",
      "Step 597: train loss = 0.107 val loss = 0.118\n",
      "Step 598: train loss = 0.107 val loss = 0.104\n",
      "Step 599: train loss = 0.108 val loss = 0.1\n",
      "Step 600: train loss = 0.104 val loss = 0.106\n",
      "Step 601: train loss = 0.108 val loss = 0.112\n",
      "Step 602: train loss = 0.103 val loss = 0.106\n",
      "Step 603: train loss = 0.105 val loss = 0.101\n",
      "Step 604: train loss = 0.104 val loss = 0.106\n",
      "Step 605: train loss = 0.104 val loss = 0.106\n",
      "Step 606: train loss = 0.103 val loss = 0.0977\n",
      "Step 607: train loss = 0.103 val loss = 0.0959\n",
      "Step 608: train loss = 0.105 val loss = 0.102\n",
      "Step 609: train loss = 0.104 val loss = 0.107\n",
      "Step 610: train loss = 0.103 val loss = 0.0988\n",
      "Step 611: train loss = 0.101 val loss = 0.0935\n",
      "Step 612: train loss = 0.103 val loss = 0.103\n",
      "Step 613: train loss = 0.1 val loss = 0.107\n",
      "Step 614: train loss = 0.102 val loss = 0.102\n",
      "Step 615: train loss = 0.101 val loss = 0.0959\n",
      "Step 616: train loss = 0.0977 val loss = 0.0927\n",
      "Step 617: train loss = 0.0994 val loss = 0.1\n",
      "Step 618: train loss = 0.0994 val loss = 0.0986\n",
      "Step 619: train loss = 0.0972 val loss = 0.0981\n",
      "Step 620: train loss = 0.101 val loss = 0.0937\n",
      "Step 621: train loss = 0.098 val loss = 0.0958\n",
      "Step 622: train loss = 0.0978 val loss = 0.0927\n",
      "Step 623: train loss = 0.0965 val loss = 0.0891\n",
      "Step 624: train loss = 0.0965 val loss = 0.0926\n",
      "Step 625: train loss = 0.097 val loss = 0.0944\n",
      "Step 626: train loss = 0.0947 val loss = 0.0993\n",
      "Step 627: train loss = 0.0945 val loss = 0.0959\n",
      "Step 628: train loss = 0.0963 val loss = 0.0918\n",
      "Step 629: train loss = 0.0966 val loss = 0.0911\n",
      "Step 630: train loss = 0.0944 val loss = 0.0907\n",
      "Step 631: train loss = 0.0951 val loss = 0.0918\n",
      "Step 632: train loss = 0.0929 val loss = 0.0889\n",
      "Step 633: train loss = 0.0939 val loss = 0.0925\n",
      "Step 634: train loss = 0.0932 val loss = 0.0896\n",
      "Step 635: train loss = 0.0929 val loss = 0.0943\n",
      "Step 636: train loss = 0.0926 val loss = 0.0884\n",
      "Step 637: train loss = 0.0922 val loss = 0.0905\n",
      "Step 638: train loss = 0.0916 val loss = 0.0888\n",
      "Step 639: train loss = 0.0913 val loss = 0.0881\n",
      "Step 640: train loss = 0.0922 val loss = 0.0885\n",
      "Step 641: train loss = 0.0921 val loss = 0.0912\n",
      "Step 642: train loss = 0.0901 val loss = 0.0916\n",
      "Step 643: train loss = 0.0887 val loss = 0.0903\n",
      "Step 644: train loss = 0.0897 val loss = 0.0896\n",
      "Step 645: train loss = 0.0872 val loss = 0.0824\n",
      "Step 646: train loss = 0.0894 val loss = 0.0866\n",
      "Step 647: train loss = 0.0883 val loss = 0.0893\n",
      "Step 648: train loss = 0.0887 val loss = 0.0838\n",
      "Step 649: train loss = 0.0887 val loss = 0.0839\n",
      "Step 650: train loss = 0.0859 val loss = 0.0863\n",
      "Step 651: train loss = 0.0867 val loss = 0.0934\n",
      "Step 652: train loss = 0.0875 val loss = 0.0905\n",
      "Step 653: train loss = 0.0861 val loss = 0.086\n",
      "Step 654: train loss = 0.087 val loss = 0.0821\n",
      "Step 655: train loss = 0.0871 val loss = 0.0867\n",
      "Step 656: train loss = 0.084 val loss = 0.0836\n",
      "Step 657: train loss = 0.0856 val loss = 0.0809\n",
      "Step 658: train loss = 0.0851 val loss = 0.0821\n",
      "Step 659: train loss = 0.083 val loss = 0.0822\n",
      "Step 660: train loss = 0.083 val loss = 0.0813\n",
      "Step 661: train loss = 0.083 val loss = 0.0839\n",
      "Step 662: train loss = 0.082 val loss = 0.08\n",
      "Step 663: train loss = 0.0839 val loss = 0.0803\n",
      "Step 664: train loss = 0.0853 val loss = 0.0796\n",
      "Step 665: train loss = 0.0817 val loss = 0.0763\n",
      "Step 666: train loss = 0.0837 val loss = 0.08\n",
      "Step 667: train loss = 0.0815 val loss = 0.0851\n",
      "Step 668: train loss = 0.0803 val loss = 0.0817\n",
      "Step 669: train loss = 0.0815 val loss = 0.0782\n",
      "Step 670: train loss = 0.0815 val loss = 0.0767\n",
      "Step 671: train loss = 0.083 val loss = 0.0779\n",
      "Step 672: train loss = 0.0824 val loss = 0.0779\n",
      "Step 673: train loss = 0.0796 val loss = 0.0767\n",
      "Step 674: train loss = 0.0785 val loss = 0.0775\n",
      "Step 675: train loss = 0.0815 val loss = 0.0795\n",
      "Step 676: train loss = 0.0793 val loss = 0.0763\n",
      "Step 677: train loss = 0.0776 val loss = 0.0749\n",
      "Step 678: train loss = 0.0801 val loss = 0.0787\n",
      "Step 679: train loss = 0.0787 val loss = 0.0795\n",
      "Step 680: train loss = 0.0785 val loss = 0.0759\n",
      "Step 681: train loss = 0.0769 val loss = 0.0741\n",
      "Step 682: train loss = 0.0759 val loss = 0.0721\n",
      "Step 683: train loss = 0.0772 val loss = 0.0743\n",
      "Step 684: train loss = 0.0766 val loss = 0.0785\n",
      "Step 685: train loss = 0.0755 val loss = 0.0752\n",
      "Step 686: train loss = 0.0763 val loss = 0.0727\n",
      "Step 687: train loss = 0.0772 val loss = 0.0727\n",
      "Step 688: train loss = 0.0751 val loss = 0.072\n",
      "Step 689: train loss = 0.077 val loss = 0.0734\n",
      "Step 690: train loss = 0.0744 val loss = 0.0728\n",
      "Step 691: train loss = 0.0726 val loss = 0.0736\n",
      "Step 692: train loss = 0.0745 val loss = 0.0713\n",
      "Step 693: train loss = 0.0732 val loss = 0.0712\n",
      "Step 694: train loss = 0.0752 val loss = 0.0702\n",
      "Step 695: train loss = 0.0749 val loss = 0.0687\n",
      "Step 696: train loss = 0.0745 val loss = 0.0726\n",
      "Step 697: train loss = 0.0756 val loss = 0.0727\n",
      "Step 698: train loss = 0.0722 val loss = 0.0689\n",
      "Step 699: train loss = 0.073 val loss = 0.0738\n",
      "Step 700: train loss = 0.0743 val loss = 0.0721\n",
      "Step 701: train loss = 0.0706 val loss = 0.0675\n",
      "Step 702: train loss = 0.071 val loss = 0.0692\n",
      "Step 703: train loss = 0.0708 val loss = 0.0674\n",
      "Step 704: train loss = 0.0709 val loss = 0.07\n",
      "Step 705: train loss = 0.0724 val loss = 0.0678\n",
      "Step 706: train loss = 0.0716 val loss = 0.0682\n",
      "Step 707: train loss = 0.0699 val loss = 0.0669\n",
      "Step 708: train loss = 0.0698 val loss = 0.0741\n",
      "Step 709: train loss = 0.0687 val loss = 0.0733\n",
      "Step 710: train loss = 0.0716 val loss = 0.0708\n",
      "Step 711: train loss = 0.068 val loss = 0.0653\n",
      "Step 712: train loss = 0.0684 val loss = 0.0707\n",
      "Step 713: train loss = 0.0685 val loss = 0.069\n",
      "Step 714: train loss = 0.0702 val loss = 0.0645\n",
      "Step 715: train loss = 0.0674 val loss = 0.065\n",
      "Step 716: train loss = 0.0702 val loss = 0.0716\n",
      "Step 717: train loss = 0.0684 val loss = 0.0686\n",
      "Step 718: train loss = 0.0688 val loss = 0.0616\n",
      "Step 719: train loss = 0.0673 val loss = 0.065\n",
      "Step 720: train loss = 0.0685 val loss = 0.0696\n",
      "Step 721: train loss = 0.067 val loss = 0.0676\n",
      "Step 722: train loss = 0.0664 val loss = 0.0628\n",
      "Step 723: train loss = 0.0651 val loss = 0.0642\n",
      "Step 724: train loss = 0.0638 val loss = 0.0667\n",
      "Step 725: train loss = 0.0655 val loss = 0.0674\n",
      "Step 726: train loss = 0.0662 val loss = 0.0659\n",
      "Step 727: train loss = 0.0654 val loss = 0.0614\n",
      "Step 728: train loss = 0.0654 val loss = 0.065\n",
      "Step 729: train loss = 0.066 val loss = 0.0641\n",
      "Step 730: train loss = 0.0651 val loss = 0.0614\n",
      "Step 731: train loss = 0.0638 val loss = 0.0581\n",
      "Step 732: train loss = 0.063 val loss = 0.0592\n",
      "Step 733: train loss = 0.0641 val loss = 0.066\n",
      "Step 734: train loss = 0.0658 val loss = 0.0642\n",
      "Step 735: train loss = 0.0618 val loss = 0.0582\n",
      "Step 736: train loss = 0.0625 val loss = 0.0601\n",
      "Step 737: train loss = 0.0637 val loss = 0.0627\n",
      "Step 738: train loss = 0.0615 val loss = 0.0626\n",
      "Step 739: train loss = 0.0634 val loss = 0.06\n",
      "Step 740: train loss = 0.0638 val loss = 0.06\n",
      "Step 741: train loss = 0.0616 val loss = 0.0604\n",
      "Step 742: train loss = 0.0616 val loss = 0.0639\n",
      "Step 743: train loss = 0.0618 val loss = 0.0641\n",
      "Step 744: train loss = 0.0629 val loss = 0.0615\n",
      "Step 745: train loss = 0.061 val loss = 0.0604\n",
      "Step 746: train loss = 0.0607 val loss = 0.0586\n",
      "Step 747: train loss = 0.061 val loss = 0.0586\n",
      "Step 748: train loss = 0.0611 val loss = 0.057\n",
      "Step 749: train loss = 0.06 val loss = 0.0582\n",
      "Step 750: train loss = 0.0611 val loss = 0.0609\n",
      "Step 751: train loss = 0.06 val loss = 0.0564\n",
      "Step 752: train loss = 0.0591 val loss = 0.0569\n",
      "Step 753: train loss = 0.0592 val loss = 0.059\n",
      "Step 754: train loss = 0.0575 val loss = 0.0609\n",
      "Step 755: train loss = 0.0588 val loss = 0.0589\n",
      "Step 756: train loss = 0.0581 val loss = 0.0543\n",
      "Step 757: train loss = 0.0572 val loss = 0.0547\n",
      "Step 758: train loss = 0.0574 val loss = 0.058\n",
      "Step 759: train loss = 0.0588 val loss = 0.0605\n",
      "Step 760: train loss = 0.0566 val loss = 0.0556\n",
      "Step 761: train loss = 0.0579 val loss = 0.0552\n",
      "Step 762: train loss = 0.0564 val loss = 0.0585\n",
      "Step 763: train loss = 0.0571 val loss = 0.0602\n",
      "Step 764: train loss = 0.0566 val loss = 0.058\n",
      "Step 765: train loss = 0.0565 val loss = 0.052\n",
      "Step 766: train loss = 0.0549 val loss = 0.0519\n",
      "Step 767: train loss = 0.0573 val loss = 0.0535\n",
      "Step 768: train loss = 0.0552 val loss = 0.0537\n",
      "Step 769: train loss = 0.0552 val loss = 0.0538\n",
      "Step 770: train loss = 0.0549 val loss = 0.0498\n",
      "Step 771: train loss = 0.0545 val loss = 0.0524\n",
      "Step 772: train loss = 0.0552 val loss = 0.0541\n",
      "Step 773: train loss = 0.0554 val loss = 0.0536\n",
      "Step 774: train loss = 0.0528 val loss = 0.0518\n",
      "Step 775: train loss = 0.0545 val loss = 0.0559\n",
      "Step 776: train loss = 0.0553 val loss = 0.0563\n",
      "Step 777: train loss = 0.055 val loss = 0.055\n",
      "Step 778: train loss = 0.0538 val loss = 0.0517\n",
      "Step 779: train loss = 0.0541 val loss = 0.0509\n",
      "Step 780: train loss = 0.0523 val loss = 0.0508\n",
      "Step 781: train loss = 0.053 val loss = 0.0486\n",
      "Step 782: train loss = 0.0538 val loss = 0.0506\n",
      "Step 783: train loss = 0.0508 val loss = 0.0507\n",
      "Step 784: train loss = 0.0529 val loss = 0.0547\n",
      "Step 785: train loss = 0.0521 val loss = 0.0554\n",
      "Step 786: train loss = 0.0523 val loss = 0.0539\n",
      "Step 787: train loss = 0.0517 val loss = 0.0492\n",
      "Step 788: train loss = 0.0518 val loss = 0.0501\n",
      "Step 789: train loss = 0.0531 val loss = 0.0495\n",
      "Step 790: train loss = 0.0513 val loss = 0.0475\n",
      "Step 791: train loss = 0.0521 val loss = 0.046\n",
      "Step 792: train loss = 0.052 val loss = 0.0469\n",
      "Step 793: train loss = 0.0521 val loss = 0.0526\n",
      "Step 794: train loss = 0.0515 val loss = 0.0526\n",
      "Step 795: train loss = 0.0508 val loss = 0.0519\n",
      "Step 796: train loss = 0.0503 val loss = 0.0495\n",
      "Step 797: train loss = 0.0507 val loss = 0.05\n",
      "Step 798: train loss = 0.0502 val loss = 0.0504\n",
      "Step 799: train loss = 0.0487 val loss = 0.048\n",
      "Step 800: train loss = 0.0501 val loss = 0.0492\n",
      "Step 801: train loss = 0.0485 val loss = 0.0481\n",
      "Step 802: train loss = 0.0499 val loss = 0.0495\n",
      "Step 803: train loss = 0.049 val loss = 0.0485\n",
      "Step 804: train loss = 0.0499 val loss = 0.0466\n",
      "Step 805: train loss = 0.0485 val loss = 0.0452\n",
      "Step 806: train loss = 0.0493 val loss = 0.0469\n",
      "Step 807: train loss = 0.0487 val loss = 0.047\n",
      "Step 808: train loss = 0.0478 val loss = 0.0464\n",
      "Step 809: train loss = 0.0488 val loss = 0.0487\n",
      "Step 810: train loss = 0.0481 val loss = 0.0483\n",
      "Step 811: train loss = 0.0482 val loss = 0.046\n",
      "Step 812: train loss = 0.0475 val loss = 0.0463\n",
      "Step 813: train loss = 0.0477 val loss = 0.0462\n",
      "Step 814: train loss = 0.0469 val loss = 0.0466\n",
      "Step 815: train loss = 0.0475 val loss = 0.0467\n",
      "Step 816: train loss = 0.0477 val loss = 0.045\n",
      "Step 817: train loss = 0.0472 val loss = 0.0453\n",
      "Step 818: train loss = 0.0471 val loss = 0.045\n",
      "Step 819: train loss = 0.0447 val loss = 0.0446\n",
      "Step 820: train loss = 0.045 val loss = 0.0465\n",
      "Step 821: train loss = 0.0469 val loss = 0.0462\n",
      "Step 822: train loss = 0.0456 val loss = 0.046\n",
      "Step 823: train loss = 0.0439 val loss = 0.044\n",
      "Step 824: train loss = 0.0455 val loss = 0.0452\n",
      "Step 825: train loss = 0.0444 val loss = 0.0464\n",
      "Step 826: train loss = 0.0448 val loss = 0.0443\n",
      "Step 827: train loss = 0.0461 val loss = 0.0453\n",
      "Step 828: train loss = 0.0449 val loss = 0.0443\n",
      "Step 829: train loss = 0.0442 val loss = 0.0422\n",
      "Step 830: train loss = 0.0448 val loss = 0.0423\n",
      "Step 831: train loss = 0.0447 val loss = 0.0438\n",
      "Step 832: train loss = 0.0435 val loss = 0.045\n",
      "Step 833: train loss = 0.0458 val loss = 0.0457\n",
      "Step 834: train loss = 0.0447 val loss = 0.0422\n",
      "Step 835: train loss = 0.0426 val loss = 0.0414\n",
      "Step 836: train loss = 0.0436 val loss = 0.0431\n",
      "Step 837: train loss = 0.0438 val loss = 0.0434\n",
      "Step 838: train loss = 0.0434 val loss = 0.0417\n",
      "Step 839: train loss = 0.0437 val loss = 0.0422\n",
      "Step 840: train loss = 0.0425 val loss = 0.0427\n",
      "Step 841: train loss = 0.0427 val loss = 0.0424\n",
      "Step 842: train loss = 0.0433 val loss = 0.0418\n",
      "Step 843: train loss = 0.0425 val loss = 0.0405\n",
      "Step 844: train loss = 0.0418 val loss = 0.0391\n",
      "Step 845: train loss = 0.0427 val loss = 0.0419\n",
      "Step 846: train loss = 0.0427 val loss = 0.0411\n",
      "Step 847: train loss = 0.0416 val loss = 0.0389\n",
      "Step 848: train loss = 0.0408 val loss = 0.0403\n",
      "Step 849: train loss = 0.0406 val loss = 0.0421\n",
      "Step 850: train loss = 0.0409 val loss = 0.0424\n",
      "Step 851: train loss = 0.0408 val loss = 0.0401\n",
      "Step 852: train loss = 0.042 val loss = 0.0398\n",
      "Step 853: train loss = 0.0404 val loss = 0.0392\n",
      "Step 854: train loss = 0.0426 val loss = 0.0417\n",
      "Step 855: train loss = 0.0402 val loss = 0.0386\n",
      "Step 856: train loss = 0.0402 val loss = 0.0393\n",
      "Step 857: train loss = 0.0402 val loss = 0.0387\n",
      "Step 858: train loss = 0.0406 val loss = 0.0401\n",
      "Step 859: train loss = 0.0406 val loss = 0.0385\n",
      "Step 860: train loss = 0.0402 val loss = 0.0395\n",
      "Step 861: train loss = 0.0402 val loss = 0.0386\n",
      "Step 862: train loss = 0.0395 val loss = 0.0386\n",
      "Step 863: train loss = 0.0384 val loss = 0.0379\n",
      "Step 864: train loss = 0.0382 val loss = 0.039\n",
      "Step 865: train loss = 0.0387 val loss = 0.041\n",
      "Step 866: train loss = 0.0409 val loss = 0.0391\n",
      "Step 867: train loss = 0.038 val loss = 0.0365\n",
      "Step 868: train loss = 0.0398 val loss = 0.0366\n",
      "Step 869: train loss = 0.0377 val loss = 0.0378\n",
      "Step 870: train loss = 0.0381 val loss = 0.0384\n",
      "Step 871: train loss = 0.0379 val loss = 0.0377\n",
      "Step 872: train loss = 0.0379 val loss = 0.0366\n",
      "Step 873: train loss = 0.0378 val loss = 0.0372\n",
      "Step 874: train loss = 0.0369 val loss = 0.0392\n",
      "Step 875: train loss = 0.0385 val loss = 0.0378\n",
      "Step 876: train loss = 0.037 val loss = 0.0347\n",
      "Step 877: train loss = 0.0374 val loss = 0.0352\n",
      "Step 878: train loss = 0.0379 val loss = 0.0363\n",
      "Step 879: train loss = 0.0368 val loss = 0.0375\n",
      "Step 880: train loss = 0.0377 val loss = 0.0364\n",
      "Step 881: train loss = 0.0367 val loss = 0.0351\n",
      "Step 882: train loss = 0.0365 val loss = 0.0342\n",
      "Step 883: train loss = 0.0373 val loss = 0.0348\n",
      "Step 884: train loss = 0.0365 val loss = 0.0352\n",
      "Step 885: train loss = 0.0361 val loss = 0.0349\n",
      "Step 886: train loss = 0.035 val loss = 0.0366\n",
      "Step 887: train loss = 0.0367 val loss = 0.0383\n",
      "Step 888: train loss = 0.0366 val loss = 0.0369\n",
      "Step 889: train loss = 0.0357 val loss = 0.0349\n",
      "Step 890: train loss = 0.0352 val loss = 0.0352\n",
      "Step 891: train loss = 0.0355 val loss = 0.0371\n",
      "Step 892: train loss = 0.0364 val loss = 0.0354\n",
      "Step 893: train loss = 0.0351 val loss = 0.035\n",
      "Step 894: train loss = 0.0353 val loss = 0.0351\n",
      "Step 895: train loss = 0.0352 val loss = 0.0352\n",
      "Step 896: train loss = 0.036 val loss = 0.034\n",
      "Step 897: train loss = 0.0347 val loss = 0.0342\n",
      "Step 898: train loss = 0.0343 val loss = 0.0339\n",
      "Step 899: train loss = 0.0344 val loss = 0.0328\n",
      "Step 900: train loss = 0.0345 val loss = 0.0314\n",
      "Step 901: train loss = 0.0345 val loss = 0.0319\n",
      "Step 902: train loss = 0.0348 val loss = 0.0351\n",
      "Step 903: train loss = 0.0334 val loss = 0.034\n",
      "Step 904: train loss = 0.0333 val loss = 0.033\n",
      "Step 905: train loss = 0.0358 val loss = 0.0318\n",
      "Step 906: train loss = 0.0347 val loss = 0.0316\n",
      "Step 907: train loss = 0.0341 val loss = 0.0321\n",
      "Step 908: train loss = 0.0324 val loss = 0.0318\n",
      "Step 909: train loss = 0.0331 val loss = 0.0327\n",
      "Step 910: train loss = 0.0333 val loss = 0.0335\n",
      "Step 911: train loss = 0.0333 val loss = 0.0332\n",
      "Step 912: train loss = 0.0321 val loss = 0.0327\n",
      "Step 913: train loss = 0.0326 val loss = 0.032\n",
      "Step 914: train loss = 0.0326 val loss = 0.0331\n",
      "Step 915: train loss = 0.033 val loss = 0.0315\n",
      "Step 916: train loss = 0.0323 val loss = 0.0317\n",
      "Step 917: train loss = 0.0324 val loss = 0.0312\n",
      "Step 918: train loss = 0.0325 val loss = 0.0322\n",
      "Step 919: train loss = 0.0315 val loss = 0.0322\n",
      "Step 920: train loss = 0.0325 val loss = 0.0329\n",
      "Step 921: train loss = 0.0316 val loss = 0.0313\n",
      "Step 922: train loss = 0.0312 val loss = 0.0311\n",
      "Step 923: train loss = 0.031 val loss = 0.0305\n",
      "Step 924: train loss = 0.0319 val loss = 0.0325\n",
      "Step 925: train loss = 0.0312 val loss = 0.0312\n",
      "Step 926: train loss = 0.0308 val loss = 0.0306\n",
      "Step 927: train loss = 0.0328 val loss = 0.0309\n",
      "Step 928: train loss = 0.0318 val loss = 0.0304\n",
      "Step 929: train loss = 0.0305 val loss = 0.0291\n",
      "Step 930: train loss = 0.0316 val loss = 0.0299\n",
      "Step 931: train loss = 0.0293 val loss = 0.0292\n",
      "Step 932: train loss = 0.0299 val loss = 0.0294\n",
      "Step 933: train loss = 0.0313 val loss = 0.0313\n",
      "Step 934: train loss = 0.0295 val loss = 0.0296\n",
      "Step 935: train loss = 0.0294 val loss = 0.0285\n",
      "Step 936: train loss = 0.0304 val loss = 0.0285\n",
      "Step 937: train loss = 0.0312 val loss = 0.0304\n",
      "Step 938: train loss = 0.0311 val loss = 0.0288\n",
      "Step 939: train loss = 0.0299 val loss = 0.0286\n",
      "Step 940: train loss = 0.0287 val loss = 0.0289\n",
      "Step 941: train loss = 0.0298 val loss = 0.0321\n",
      "Step 942: train loss = 0.0297 val loss = 0.0309\n",
      "Step 943: train loss = 0.0297 val loss = 0.0269\n",
      "Step 944: train loss = 0.0287 val loss = 0.0266\n",
      "Step 945: train loss = 0.0288 val loss = 0.0277\n",
      "Step 946: train loss = 0.0299 val loss = 0.0298\n",
      "Step 947: train loss = 0.0289 val loss = 0.0287\n",
      "Step 948: train loss = 0.0295 val loss = 0.0283\n",
      "Step 949: train loss = 0.029 val loss = 0.0278\n",
      "Step 950: train loss = 0.0295 val loss = 0.0271\n",
      "Step 951: train loss = 0.029 val loss = 0.0276\n",
      "Step 952: train loss = 0.0282 val loss = 0.0275\n",
      "Step 953: train loss = 0.0294 val loss = 0.0269\n",
      "Step 954: train loss = 0.0289 val loss = 0.0269\n",
      "Step 955: train loss = 0.0289 val loss = 0.0278\n",
      "Step 956: train loss = 0.0283 val loss = 0.028\n",
      "Step 957: train loss = 0.0284 val loss = 0.0291\n",
      "Step 958: train loss = 0.0285 val loss = 0.0282\n",
      "Step 959: train loss = 0.0286 val loss = 0.0272\n",
      "Step 960: train loss = 0.0281 val loss = 0.0264\n",
      "Step 961: train loss = 0.0286 val loss = 0.0272\n",
      "Step 962: train loss = 0.0273 val loss = 0.0287\n",
      "Step 963: train loss = 0.0284 val loss = 0.0284\n",
      "Step 964: train loss = 0.0279 val loss = 0.0266\n",
      "Step 965: train loss = 0.0283 val loss = 0.0274\n",
      "Step 966: train loss = 0.0274 val loss = 0.0268\n",
      "Step 967: train loss = 0.028 val loss = 0.0274\n",
      "Step 968: train loss = 0.0275 val loss = 0.0274\n",
      "Step 969: train loss = 0.0277 val loss = 0.0269\n",
      "Step 970: train loss = 0.0277 val loss = 0.0276\n",
      "Step 971: train loss = 0.0269 val loss = 0.0259\n",
      "Step 972: train loss = 0.0267 val loss = 0.0266\n",
      "Step 973: train loss = 0.027 val loss = 0.0275\n",
      "Step 974: train loss = 0.027 val loss = 0.0259\n",
      "Step 975: train loss = 0.027 val loss = 0.0249\n",
      "Step 976: train loss = 0.0262 val loss = 0.0252\n",
      "Step 977: train loss = 0.0268 val loss = 0.0274\n",
      "Step 978: train loss = 0.0272 val loss = 0.0274\n",
      "Step 979: train loss = 0.0266 val loss = 0.0256\n",
      "Step 980: train loss = 0.0264 val loss = 0.0255\n",
      "Step 981: train loss = 0.0254 val loss = 0.0259\n",
      "Step 982: train loss = 0.0259 val loss = 0.0262\n",
      "Step 983: train loss = 0.0257 val loss = 0.0264\n",
      "Step 984: train loss = 0.026 val loss = 0.0263\n",
      "Step 985: train loss = 0.0255 val loss = 0.0261\n",
      "Step 986: train loss = 0.0261 val loss = 0.0276\n",
      "Step 987: train loss = 0.0262 val loss = 0.0261\n",
      "Step 988: train loss = 0.026 val loss = 0.0241\n",
      "Step 989: train loss = 0.0259 val loss = 0.0247\n",
      "Step 990: train loss = 0.0251 val loss = 0.0258\n",
      "Step 991: train loss = 0.0251 val loss = 0.0263\n",
      "Step 992: train loss = 0.0247 val loss = 0.0245\n",
      "Step 993: train loss = 0.0249 val loss = 0.0248\n",
      "Step 994: train loss = 0.0255 val loss = 0.0252\n",
      "Step 995: train loss = 0.0252 val loss = 0.0245\n",
      "Step 996: train loss = 0.024 val loss = 0.023\n",
      "Step 997: train loss = 0.025 val loss = 0.024\n",
      "Step 998: train loss = 0.0258 val loss = 0.0259\n",
      "Step 999: train loss = 0.0242 val loss = 0.0261\n"
     ]
    }
   ],
   "source": [
    "model = Model([8, 16, 32])\n",
    "model.to(\"cuda:0\")\n",
    "train_loop(model, torch.optim.Adam(model.parameters()), train, val, batch_size=1000, n_batches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model.to_tensor(train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (16) must match the size of tensor b (32) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Benoit\\Documents\\projets\\bfavier.github.io\\introduction_to_deep_learning\\notebooks\\introduction_to_deep_learning_TP.ipynb Cellule 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Benoit/Documents/projets/bfavier.github.io/introduction_to_deep_learning/notebooks/introduction_to_deep_learning_TP.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mdecoder(model\u001b[39m.\u001b[39;49mencoder(X))\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\Benoit\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\Benoit\\Documents\\projets\\bfavier.github.io\\introduction_to_deep_learning\\notebooks\\introduction_to_deep_learning_TP.ipynb Cellule 11\u001b[0m in \u001b[0;36mDecoder.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Benoit/Documents/projets/bfavier.github.io/introduction_to_deep_learning/notebooks/introduction_to_deep_learning_TP.ipynb#X21sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     X \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39minterpolate(X, scale_factor\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m\"\u001b[39m, align_corners\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Benoit/Documents/projets/bfavier.github.io/introduction_to_deep_learning/notebooks/introduction_to_deep_learning_TP.ipynb#X21sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     Y \u001b[39m=\u001b[39m bn(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(activ(X)))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Benoit/Documents/projets/bfavier.github.io/introduction_to_deep_learning/notebooks/introduction_to_deep_learning_TP.ipynb#X21sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     X \u001b[39m=\u001b[39m Y \u001b[39m+\u001b[39;49m X\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Benoit/Documents/projets/bfavier.github.io/introduction_to_deep_learning/notebooks/introduction_to_deep_learning_TP.ipynb#X21sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mreturn\u001b[39;00m X\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (16) must match the size of tensor b (32) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "model.decoder(model.encoder(X)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (2): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 8, 3]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[8, 16, 32][-2::-1] + [3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2017a09ab1f54c7a6a1af190715fd60264df4a93389a277e03c18d947a6e489"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Benoit\\miniconda3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "import re\n",
    "from typing import Callable, Iterable, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecialToken:\n",
    "    \"\"\"\n",
    "    A special token for tokenizers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, string: str):\n",
    "        self.string = string.upper()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<{self.string}>\"\n",
    "    \n",
    "    def __eq__(self, other) -> bool:\n",
    "        if isinstance(other, SpecialToken):\n",
    "            return self.string == other.string\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash(self.string)\n",
    "\n",
    "\n",
    "class Tokenizer:\n",
    "    \"\"\"\n",
    "    A simple word tokenizer\n",
    "    \"\"\"\n",
    "\n",
    "    word_pattern = re.compile(R\"\\w+|\\d+|[^\\w\\d\\s]\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Tokenizer({len(self.vocabulary)} tokens)\"\n",
    "\n",
    "    def __init__(self, corpus: Iterable[str], min_frequency: float = 1.0E-6):\n",
    "        words = [word for document in corpus for word in self._split(document)]\n",
    "        word_counts = Counter(words)\n",
    "        word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        self.vocabulary = [k for k, v in word_counts if v/len(words) >= min_frequency] + [SpecialToken(\"UNKNOWN\"), SpecialToken(\"END\"), SpecialToken(\"PAD\")]\n",
    "        self.map = {word: i for i, word in enumerate(self.vocabulary)}\n",
    "\n",
    "    def split(self, document: str) -> list[str]:\n",
    "        return self.decode(self.encode(document))\n",
    "\n",
    "    def encode(self, document: str) -> list[int]:\n",
    "        return [self.map.get(word, self.UNKNOWN) for word in self._split(document)]\n",
    "\n",
    "    def decode(self, encoded: list[int]) -> list[str]:\n",
    "        return [i.string if isinstance(i, SpecialToken) else self.vocabulary[i] for i in encoded]\n",
    "\n",
    "    def _split(self, document: str) -> list[str]:\n",
    "        return self.word_pattern.findall(document)\n",
    "\n",
    "    @property\n",
    "    def PAD(self) -> SpecialToken:\n",
    "        return self.map[SpecialToken(\"PAD\")]\n",
    "    \n",
    "    @property\n",
    "    def END(self) -> SpecialToken:\n",
    "        return self.map[SpecialToken(\"END\")]\n",
    "    \n",
    "    @property\n",
    "    def UNKNOWN(self) -> SpecialToken:\n",
    "        return self.map[SpecialToken(\"UNKNOWN\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'airline_sentiment'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/Twitter_US_Airline_Sentiment.csv\")\n",
    "labels = ['negative', 'neutral', 'positive']\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer(4314 tokens)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(df.text, min_frequency=1.0E-5)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@JetBlue Complete waste of an entire day. Pathetic.\n",
      "negative\n",
      "['@', 'JetBlue', <UNKNOWN>, 'waste', 'of', 'an', 'entire', 'day', '.', 'Pathetic', '.']\n",
      "\n",
      "@united you Cancelled Flight my flight. I wait in line to get rebooked, when I'm at the front you make me go to another gate and I lose my place.\n",
      "negative\n",
      "['@', 'united', 'you', 'Cancelled', 'Flight', 'my', 'flight', '.', 'I', 'wait', 'in', 'line', 'to', 'get', 'rebooked', ',', 'when', 'I', \"'\", 'm', 'at', 'the', 'front', 'you', 'make', 'me', 'go', 'to', 'another', 'gate', 'and', 'I', 'lose', 'my', 'place', '.']\n",
      "\n",
      "@SouthwestAir bumped me to preboard on both flights (because I'm fat?) Whatever the reason, thanks!\n",
      "positive\n",
      "['@', 'SouthwestAir', 'bumped', 'me', 'to', 'preboard', 'on', 'both', 'flights', '(', 'because', 'I', \"'\", 'm', 'fat', '?', ')', <UNKNOWN>, 'the', 'reason', ',', 'thanks', '!']\n",
      "\n",
      "@SouthwestAir weather where? And at what time Cancelled Flighted? No I can't because meeting was today.\n",
      "negative\n",
      "['@', 'SouthwestAir', 'weather', 'where', '?', 'And', 'at', 'what', 'time', 'Cancelled', 'Flighted', '?', 'No', 'I', 'can', \"'\", 't', 'because', 'meeting', 'was', 'today', '.']\n",
      "\n",
      "@united Both flights went great and improved my view of your airline, cheers! Flight attendents on UA1022 deserve a raise\n",
      "positive\n",
      "['@', 'united', 'Both', 'flights', 'went', 'great', 'and', <UNKNOWN>, 'my', 'view', 'of', 'your', 'airline', ',', <UNKNOWN>, '!', 'Flight', <UNKNOWN>, 'on', <UNKNOWN>, 'deserve', 'a', 'raise']\n",
      "\n",
      "@JetBlue Its poor Flight management. There is   no reason why a scheduled 8:00  pm  flight to takr off At 11:00pm .\n",
      "negative\n",
      "['@', 'JetBlue', 'Its', 'poor', 'Flight', 'management', '.', 'There', 'is', 'no', 'reason', 'why', 'a', 'scheduled', '8', ':', '00', 'pm', 'flight', 'to', <UNKNOWN>, 'off', 'At', '11', ':', '00pm', '.']\n",
      "\n",
      "@united Did you get your 757 Model?\n",
      "neutral\n",
      "['@', 'united', 'Did', 'you', 'get', 'your', '757', <UNKNOWN>, '?']\n",
      "\n",
      "@SouthwestAir trying to rebook flight. On hold for 23 mins before disconnected and now almost 40 mins? Unbelievable. http://t.co/0BJNz4EIX5\n",
      "negative\n",
      "['@', 'SouthwestAir', 'trying', 'to', 'rebook', 'flight', '.', 'On', 'hold', 'for', '23', 'mins', 'before', 'disconnected', 'and', 'now', 'almost', '40', 'mins', '?', 'Unbelievable', '.', 'http', ':', '/', '/', 't', '.', 'co', '/', <UNKNOWN>]\n",
      "\n",
      "@USAirways Flight 2069 from JFK to Charlotte, then 3750 from Charlotte to Birmingham. 2 previous flights to HSV were Cancelled Flightled.\n",
      "negative\n",
      "['@', 'USAirways', 'Flight', <UNKNOWN>, 'from', 'JFK', 'to', 'Charlotte', ',', 'then', <UNKNOWN>, 'from', 'Charlotte', 'to', 'Birmingham', '.', '2', 'previous', 'flights', 'to', <UNKNOWN>, 'were', 'Cancelled', 'Flightled', '.']\n",
      "\n",
      "@SouthwestAir want to explain why I was on hold for 2+ hrs tonight trying to reach customer service only to learn they're only there Mon-Fr?\n",
      "negative\n",
      "['@', 'SouthwestAir', 'want', 'to', 'explain', 'why', 'I', 'was', 'on', 'hold', 'for', '2', '+', 'hrs', 'tonight', 'trying', 'to', 'reach', 'customer', 'service', 'only', 'to', 'learn', 'they', \"'\", 're', 'only', 'there', 'Mon', '-', <UNKNOWN>, '?']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, row in df.sample(n=10).iterrows():\n",
    "    print(row.text)\n",
    "    print(row.airline_sentiment)\n",
    "    print(tokenizer.split(row.text))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.sample(frac=0.7)\n",
    "df = df.drop(index=df_train.index)\n",
    "df_val = df.sample(frac=0.5)\n",
    "df_test = df.drop(index=df_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted: torch.Tensor, target: torch.Tensor):\n",
    "    assert target.shape == predicted.shape\n",
    "    assert target.dtype == torch.long\n",
    "    assert predicted.dtype == torch.long\n",
    "    with torch.no_grad():\n",
    "        return torch.mean((predicted == target).float()).cpu().item()\n",
    "\n",
    "\n",
    "def input_to_tensor(df: pd.DataFrame, tokenizer: Tokenizer) -> torch.Tensor:\n",
    "    encoded = [tokenizer.encode(document) for document in df['text']]\n",
    "    L = max([len(doc) for doc in encoded])\n",
    "    encoded = [doc + [tokenizer.PAD]*(L - len(doc)) for doc in encoded]\n",
    "    return torch.tensor(encoded, dtype=torch.long)\n",
    "\n",
    "\n",
    "def target_to_tensor(df: pd.DataFrame) -> torch.Tensor:\n",
    "    map = {k: v for v, k in enumerate(labels)}\n",
    "    return torch.tensor([map[label] for label in df[\"airline_sentiment\"]], dtype=torch.long)\n",
    "\n",
    "\n",
    "def data_to_tensor(df: pd.DataFrame, tokenizer: Tokenizer) -> tuple[torch.Tensor]:\n",
    "    return (input_to_tensor(df, tokenizer), target_to_tensor(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batchifyer:\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer: Tokenizer, n_batches: int, batch_size: Optional[int]):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.n_batches = n_batches\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        shuffled = df.sample(frac=1.)\n",
    "        return (self._batch(shuffled, i) for i in range(self.n_batches))\n",
    "    \n",
    "    def _batch(self, shuffled: pd.DataFrame, i: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        batch_size = self.batch_size or len(shuffled) // self.n_batches\n",
    "        subset = shuffled.iloc[i*batch_size:(i+1)*batch_size]\n",
    "        return data_to_tensor(subset, self.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model: torch.nn.Module, optimizer: torch.optim.Optimizer, train_data: Iterable[tuple[torch.Tensor]], val_data: Iterable[tuple[torch.Tensor]], n_steps: int = 1000, patience: int = 100, keep_best: bool = True):\n",
    "    \"\"\"\n",
    "    train the model for the specified number of steps, or untilearly stopping\n",
    "    \"\"\"\n",
    "    best_state = deepcopy(model.state_dict())\n",
    "    best_step = 0\n",
    "    best_metric = 0.\n",
    "    try:\n",
    "        for step in range(n_steps):\n",
    "            optimizer.zero_grad()\n",
    "            # train loss\n",
    "            model.train()\n",
    "            losses = []\n",
    "            for x, y in train_data:\n",
    "                loss = model.loss(x, y)\n",
    "                loss.backward()\n",
    "                losses.append(loss.item())\n",
    "            loss = sum(losses)/len(losses)\n",
    "            # val metric\n",
    "            model.eval()\n",
    "            metrics = []\n",
    "            for x, y in val_data:\n",
    "                metrics.append(model.metric(x, y))\n",
    "            metric = sum(metrics) / len(metrics)\n",
    "            # checkpointing\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_step = step\n",
    "                if keep_best:\n",
    "                    best_state = deepcopy(model.state_dict())\n",
    "            elif step - best_step > patience:\n",
    "                print(\"early stoping\")\n",
    "                break\n",
    "            # optimizer steping\n",
    "            optimizer.step()\n",
    "            # printing\n",
    "            print(f\"Step {step}: loss = {loss:.3g} metric = {metric:.2%}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"interrupted by user\")\n",
    "    if keep_best:\n",
    "        model.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1\n",
    "\n",
    "Implémenter et entraîner un réseau récurrent pour classifier les tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes: int, tokenizer: Tokenizer, in_features: int, hidden_state_features: int, activation: Callable = torch.relu):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.hidden_state_features = hidden_state_features\n",
    "        self.embedding = torch.nn.Embedding(len(tokenizer.vocabulary), in_features)\n",
    "        self.linear = torch.nn.Linear(in_features + hidden_state_features, in_features + hidden_state_features)\n",
    "        self.activation = activation\n",
    "        self.contract = torch.nn.Linear(in_features + hidden_state_features, hidden_state_features)\n",
    "        self.normalization = torch.nn.LayerNorm(hidden_state_features)\n",
    "        self.output = torch.nn.Linear(hidden_state_features, n_classes)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        X : torch.Tensor\n",
    "            tensor of long of shape (N, L)\n",
    "        \"\"\"\n",
    "        X = X.to(self.device)\n",
    "        N, L = X.shape\n",
    "        H = torch.zeros((N, self.hidden_state_features), dtype=torch.float32, device=X.device)\n",
    "        for x in X.transpose(0, 1):\n",
    "            I = self.embedding(x)\n",
    "            T = torch.cat([I, H], dim=1)\n",
    "            T = self.linear(T)\n",
    "            T = self.activation(T)\n",
    "            T = self.contract(T)\n",
    "            H = torch.where(x.unsqueeze(1) == self.tokenizer.PAD, H, T)\n",
    "        return self.output(H)\n",
    "    \n",
    "    def predict(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            Y = self(X)\n",
    "        return Y.max(dim=1).indices\n",
    "    \n",
    "    def loss(self, X: torch.Tensor, Y: torch.Tensor) -> torch.Tensor:\n",
    "        y_pred = self(X)\n",
    "        return F.cross_entropy(y_pred, Y.to(y_pred.device))\n",
    "\n",
    "    def metric(self, X: torch.Tensor, Y: torch.Tensor) -> torch.Tensor:\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy(y_pred, Y.to(y_pred.device))\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return self.output.weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 1.12 metric = 21.08%\n",
      "Step 1: loss = 1.11 metric = 22.97%\n",
      "Step 2: loss = 1.1 metric = 24.20%\n",
      "Step 3: loss = 1.1 metric = 30.97%\n",
      "Step 4: loss = 1.09 metric = 36.77%\n",
      "Step 5: loss = 1.08 metric = 50.55%\n",
      "Step 6: loss = 1.07 metric = 52.60%\n",
      "Step 7: loss = 1.06 metric = 54.37%\n",
      "Step 8: loss = 1.06 metric = 56.42%\n",
      "Step 9: loss = 1.05 metric = 57.45%\n",
      "Step 10: loss = 1.04 metric = 58.79%\n",
      "Step 11: loss = 1.03 metric = 60.25%\n",
      "Step 12: loss = 1.03 metric = 61.04%\n",
      "Step 13: loss = 1.02 metric = 61.48%\n",
      "Step 14: loss = 1.01 metric = 61.75%\n",
      "Step 15: loss = 1.01 metric = 61.93%\n",
      "Step 16: loss = 0.999 metric = 62.04%\n",
      "Step 17: loss = 0.992 metric = 62.18%\n",
      "Step 18: loss = 0.986 metric = 62.20%\n",
      "Step 19: loss = 0.98 metric = 62.23%\n",
      "Step 20: loss = 0.974 metric = 62.23%\n",
      "Step 21: loss = 0.968 metric = 62.23%\n",
      "Step 22: loss = 0.963 metric = 62.25%\n",
      "Step 23: loss = 0.957 metric = 62.25%\n",
      "Step 24: loss = 0.952 metric = 62.25%\n",
      "Step 25: loss = 0.947 metric = 62.25%\n",
      "Step 26: loss = 0.942 metric = 62.25%\n",
      "Step 27: loss = 0.938 metric = 62.25%\n",
      "Step 28: loss = 0.933 metric = 62.25%\n",
      "Step 29: loss = 0.929 metric = 62.25%\n",
      "Step 30: loss = 0.925 metric = 62.25%\n",
      "Step 31: loss = 0.922 metric = 62.25%\n",
      "Step 32: loss = 0.918 metric = 62.25%\n",
      "Step 33: loss = 0.915 metric = 62.25%\n",
      "Step 34: loss = 0.912 metric = 62.25%\n",
      "Step 35: loss = 0.909 metric = 62.25%\n",
      "Step 36: loss = 0.907 metric = 62.25%\n",
      "Step 37: loss = 0.904 metric = 62.25%\n",
      "Step 38: loss = 0.902 metric = 62.25%\n",
      "Step 39: loss = 0.9 metric = 62.25%\n",
      "Step 40: loss = 0.898 metric = 62.25%\n",
      "Step 41: loss = 0.897 metric = 62.25%\n",
      "Step 42: loss = 0.895 metric = 62.25%\n",
      "Step 43: loss = 0.894 metric = 62.25%\n",
      "Step 44: loss = 0.893 metric = 62.25%\n",
      "Step 45: loss = 0.892 metric = 62.25%\n",
      "Step 46: loss = 0.891 metric = 62.25%\n",
      "Step 47: loss = 0.89 metric = 62.25%\n",
      "Step 48: loss = 0.889 metric = 62.25%\n",
      "Step 49: loss = 0.888 metric = 62.25%\n",
      "Step 50: loss = 0.887 metric = 62.25%\n",
      "Step 51: loss = 0.886 metric = 62.25%\n",
      "Step 52: loss = 0.885 metric = 62.25%\n",
      "Step 53: loss = 0.884 metric = 62.25%\n",
      "Step 54: loss = 0.883 metric = 62.25%\n",
      "Step 55: loss = 0.882 metric = 62.25%\n",
      "Step 56: loss = 0.881 metric = 62.25%\n",
      "Step 57: loss = 0.88 metric = 62.25%\n",
      "Step 58: loss = 0.879 metric = 62.25%\n",
      "Step 59: loss = 0.878 metric = 62.25%\n",
      "Step 60: loss = 0.877 metric = 62.25%\n",
      "Step 61: loss = 0.876 metric = 62.25%\n",
      "Step 62: loss = 0.875 metric = 62.25%\n",
      "Step 63: loss = 0.874 metric = 62.25%\n",
      "Step 64: loss = 0.873 metric = 62.25%\n",
      "Step 65: loss = 0.872 metric = 62.25%\n",
      "Step 66: loss = 0.871 metric = 62.25%\n",
      "Step 67: loss = 0.871 metric = 62.25%\n",
      "Step 68: loss = 0.87 metric = 62.25%\n",
      "Step 69: loss = 0.869 metric = 62.25%\n",
      "Step 70: loss = 0.868 metric = 62.25%\n",
      "Step 71: loss = 0.867 metric = 62.25%\n",
      "Step 72: loss = 0.867 metric = 62.25%\n",
      "Step 73: loss = 0.866 metric = 62.25%\n",
      "Step 74: loss = 0.865 metric = 62.25%\n",
      "Step 75: loss = 0.864 metric = 62.25%\n",
      "Step 76: loss = 0.863 metric = 62.25%\n",
      "Step 77: loss = 0.863 metric = 62.25%\n",
      "Step 78: loss = 0.862 metric = 62.25%\n",
      "Step 79: loss = 0.861 metric = 62.25%\n",
      "Step 80: loss = 0.86 metric = 62.25%\n",
      "Step 81: loss = 0.859 metric = 62.25%\n",
      "Step 82: loss = 0.859 metric = 62.25%\n",
      "Step 83: loss = 0.858 metric = 62.25%\n",
      "Step 84: loss = 0.857 metric = 62.25%\n",
      "Step 85: loss = 0.856 metric = 62.25%\n",
      "Step 86: loss = 0.856 metric = 62.25%\n",
      "Step 87: loss = 0.855 metric = 62.25%\n",
      "Step 88: loss = 0.854 metric = 62.25%\n",
      "Step 89: loss = 0.853 metric = 62.25%\n",
      "Step 90: loss = 0.853 metric = 62.25%\n",
      "Step 91: loss = 0.852 metric = 62.25%\n",
      "Step 92: loss = 0.851 metric = 62.25%\n",
      "Step 93: loss = 0.85 metric = 62.25%\n",
      "Step 94: loss = 0.85 metric = 62.25%\n",
      "Step 95: loss = 0.849 metric = 62.25%\n",
      "Step 96: loss = 0.848 metric = 62.25%\n",
      "Step 97: loss = 0.847 metric = 62.25%\n",
      "Step 98: loss = 0.847 metric = 62.25%\n",
      "Step 99: loss = 0.846 metric = 62.25%\n",
      "Step 100: loss = 0.845 metric = 62.25%\n",
      "Step 101: loss = 0.844 metric = 62.25%\n",
      "Step 102: loss = 0.843 metric = 62.25%\n",
      "Step 103: loss = 0.843 metric = 62.45%\n",
      "Step 104: loss = 0.842 metric = 62.59%\n",
      "Step 105: loss = 0.841 metric = 62.64%\n",
      "Step 106: loss = 0.84 metric = 62.68%\n",
      "Step 107: loss = 0.839 metric = 62.77%\n",
      "Step 108: loss = 0.839 metric = 62.75%\n",
      "Step 109: loss = 0.838 metric = 62.75%\n",
      "Step 110: loss = 0.837 metric = 62.75%\n",
      "Step 111: loss = 0.836 metric = 62.89%\n",
      "Step 112: loss = 0.835 metric = 62.89%\n",
      "Step 113: loss = 0.834 metric = 62.89%\n",
      "Step 114: loss = 0.833 metric = 62.86%\n",
      "Step 115: loss = 0.832 metric = 62.93%\n",
      "Step 116: loss = 0.831 metric = 62.91%\n",
      "Step 117: loss = 0.83 metric = 62.89%\n",
      "Step 118: loss = 0.829 metric = 63.00%\n",
      "Step 119: loss = 0.828 metric = 63.02%\n",
      "Step 120: loss = 0.827 metric = 63.16%\n",
      "Step 121: loss = 0.826 metric = 63.23%\n",
      "Step 122: loss = 0.825 metric = 63.27%\n",
      "Step 123: loss = 0.824 metric = 63.32%\n",
      "Step 124: loss = 0.823 metric = 63.41%\n",
      "Step 125: loss = 0.822 metric = 63.50%\n",
      "Step 126: loss = 0.82 metric = 63.64%\n",
      "Step 127: loss = 0.819 metric = 63.71%\n",
      "Step 128: loss = 0.818 metric = 63.87%\n",
      "Step 129: loss = 0.816 metric = 63.96%\n",
      "Step 130: loss = 0.815 metric = 64.25%\n",
      "Step 131: loss = 0.814 metric = 64.32%\n",
      "Step 132: loss = 0.812 metric = 64.41%\n",
      "Step 133: loss = 0.81 metric = 64.53%\n",
      "Step 134: loss = 0.809 metric = 64.62%\n",
      "Step 135: loss = 0.807 metric = 64.64%\n",
      "Step 136: loss = 0.805 metric = 64.66%\n",
      "Step 137: loss = 0.803 metric = 64.69%\n",
      "Step 138: loss = 0.8 metric = 64.82%\n",
      "Step 139: loss = 0.798 metric = 64.87%\n",
      "Step 140: loss = 0.795 metric = 64.96%\n",
      "Step 141: loss = 0.793 metric = 65.10%\n",
      "Step 142: loss = 0.79 metric = 65.30%\n",
      "Step 143: loss = 0.786 metric = 65.55%\n",
      "Step 144: loss = 0.783 metric = 65.71%\n",
      "Step 145: loss = 0.779 metric = 65.92%\n",
      "Step 146: loss = 0.775 metric = 66.01%\n",
      "Step 147: loss = 0.771 metric = 66.23%\n",
      "Step 148: loss = 0.767 metric = 66.33%\n",
      "Step 149: loss = 0.763 metric = 66.39%\n",
      "Step 150: loss = 0.76 metric = 66.21%\n",
      "Step 151: loss = 0.757 metric = 66.21%\n",
      "Step 152: loss = 0.755 metric = 66.35%\n",
      "Step 153: loss = 0.752 metric = 66.55%\n",
      "Step 154: loss = 0.751 metric = 66.26%\n",
      "Step 155: loss = 0.749 metric = 66.67%\n",
      "Step 156: loss = 0.749 metric = 66.21%\n",
      "Step 157: loss = 0.744 metric = 66.35%\n",
      "Step 158: loss = 0.745 metric = 66.69%\n",
      "Step 159: loss = 0.74 metric = 66.37%\n",
      "Step 160: loss = 0.739 metric = 66.39%\n",
      "Step 161: loss = 0.734 metric = 66.80%\n",
      "Step 162: loss = 0.734 metric = 67.03%\n",
      "Step 163: loss = 0.73 metric = 66.80%\n",
      "Step 164: loss = 0.729 metric = 66.78%\n",
      "Step 165: loss = 0.725 metric = 67.01%\n",
      "Step 166: loss = 0.724 metric = 67.17%\n",
      "Step 167: loss = 0.721 metric = 67.26%\n",
      "Step 168: loss = 0.72 metric = 67.12%\n",
      "Step 169: loss = 0.718 metric = 67.17%\n",
      "Step 170: loss = 0.715 metric = 67.46%\n",
      "Step 171: loss = 0.714 metric = 67.85%\n",
      "Step 172: loss = 0.711 metric = 67.96%\n",
      "Step 173: loss = 0.71 metric = 68.06%\n",
      "Step 174: loss = 0.708 metric = 68.12%\n",
      "Step 175: loss = 0.706 metric = 68.31%\n",
      "Step 176: loss = 0.704 metric = 68.42%\n",
      "Step 177: loss = 0.702 metric = 68.35%\n",
      "Step 178: loss = 0.7 metric = 68.44%\n",
      "Step 179: loss = 0.698 metric = 68.72%\n",
      "Step 180: loss = 0.696 metric = 68.85%\n",
      "Step 181: loss = 0.694 metric = 68.76%\n",
      "Step 182: loss = 0.692 metric = 68.99%\n",
      "Step 183: loss = 0.69 metric = 69.01%\n",
      "Step 184: loss = 0.688 metric = 69.17%\n",
      "Step 185: loss = 0.686 metric = 69.38%\n",
      "Step 186: loss = 0.685 metric = 69.47%\n",
      "Step 187: loss = 0.682 metric = 69.58%\n",
      "Step 188: loss = 0.681 metric = 69.65%\n",
      "Step 189: loss = 0.678 metric = 69.88%\n",
      "Step 190: loss = 0.677 metric = 69.83%\n",
      "Step 191: loss = 0.675 metric = 70.10%\n",
      "Step 192: loss = 0.673 metric = 70.22%\n",
      "Step 193: loss = 0.671 metric = 70.26%\n",
      "Step 194: loss = 0.669 metric = 70.38%\n",
      "Step 195: loss = 0.667 metric = 70.54%\n",
      "Step 196: loss = 0.665 metric = 70.72%\n",
      "Step 197: loss = 0.663 metric = 70.72%\n",
      "Step 198: loss = 0.661 metric = 70.95%\n",
      "Step 199: loss = 0.659 metric = 71.04%\n",
      "Step 200: loss = 0.657 metric = 71.04%\n",
      "Step 201: loss = 0.655 metric = 71.27%\n",
      "Step 202: loss = 0.654 metric = 71.36%\n",
      "Step 203: loss = 0.652 metric = 71.43%\n",
      "Step 204: loss = 0.65 metric = 71.58%\n",
      "Step 205: loss = 0.648 metric = 71.61%\n",
      "Step 206: loss = 0.646 metric = 71.86%\n",
      "Step 207: loss = 0.644 metric = 72.15%\n",
      "Step 208: loss = 0.642 metric = 72.13%\n",
      "Step 209: loss = 0.64 metric = 72.27%\n",
      "Step 210: loss = 0.638 metric = 72.61%\n",
      "Step 211: loss = 0.636 metric = 72.52%\n",
      "Step 212: loss = 0.634 metric = 72.70%\n",
      "Step 213: loss = 0.632 metric = 72.75%\n",
      "Step 214: loss = 0.63 metric = 72.88%\n",
      "Step 215: loss = 0.629 metric = 72.93%\n",
      "Step 216: loss = 0.627 metric = 73.22%\n",
      "Step 217: loss = 0.625 metric = 73.29%\n",
      "Step 218: loss = 0.623 metric = 73.41%\n",
      "Step 219: loss = 0.621 metric = 73.25%\n",
      "Step 220: loss = 0.619 metric = 73.38%\n",
      "Step 221: loss = 0.617 metric = 73.43%\n",
      "Step 222: loss = 0.615 metric = 73.52%\n",
      "Step 223: loss = 0.613 metric = 73.68%\n",
      "Step 224: loss = 0.611 metric = 73.72%\n",
      "Step 225: loss = 0.609 metric = 73.86%\n",
      "Step 226: loss = 0.607 metric = 73.88%\n",
      "Step 227: loss = 0.605 metric = 74.02%\n",
      "Step 228: loss = 0.603 metric = 74.13%\n",
      "Step 229: loss = 0.601 metric = 74.16%\n",
      "Step 230: loss = 0.599 metric = 74.34%\n",
      "Step 231: loss = 0.597 metric = 74.43%\n",
      "Step 232: loss = 0.594 metric = 74.52%\n",
      "Step 233: loss = 0.592 metric = 74.75%\n",
      "Step 234: loss = 0.59 metric = 74.77%\n",
      "Step 235: loss = 0.588 metric = 74.89%\n",
      "Step 236: loss = 0.586 metric = 75.02%\n",
      "Step 237: loss = 0.584 metric = 75.16%\n",
      "Step 238: loss = 0.582 metric = 75.36%\n",
      "Step 239: loss = 0.58 metric = 75.25%\n",
      "Step 240: loss = 0.578 metric = 75.55%\n",
      "Step 241: loss = 0.577 metric = 75.09%\n",
      "Step 242: loss = 0.579 metric = 76.00%\n",
      "Step 243: loss = 0.574 metric = 75.16%\n",
      "Step 244: loss = 0.569 metric = 75.91%\n",
      "Step 245: loss = 0.568 metric = 76.07%\n",
      "Step 246: loss = 0.567 metric = 75.55%\n",
      "Step 247: loss = 0.565 metric = 76.34%\n",
      "Step 248: loss = 0.561 metric = 76.39%\n",
      "Step 249: loss = 0.561 metric = 75.75%\n",
      "Step 250: loss = 0.559 metric = 76.87%\n",
      "Step 251: loss = 0.555 metric = 76.78%\n",
      "Step 252: loss = 0.555 metric = 76.34%\n",
      "Step 253: loss = 0.553 metric = 77.14%\n",
      "Step 254: loss = 0.549 metric = 77.09%\n",
      "Step 255: loss = 0.55 metric = 76.57%\n",
      "Step 256: loss = 0.547 metric = 77.28%\n",
      "Step 257: loss = 0.543 metric = 77.23%\n",
      "Step 258: loss = 0.545 metric = 77.05%\n",
      "Step 259: loss = 0.541 metric = 77.46%\n",
      "Step 260: loss = 0.538 metric = 77.50%\n",
      "Step 261: loss = 0.539 metric = 77.03%\n",
      "Step 262: loss = 0.534 metric = 77.62%\n",
      "Step 263: loss = 0.533 metric = 77.71%\n",
      "Step 264: loss = 0.532 metric = 77.35%\n",
      "Step 265: loss = 0.527 metric = 77.89%\n",
      "Step 266: loss = 0.527 metric = 77.94%\n",
      "Step 267: loss = 0.524 metric = 77.87%\n",
      "Step 268: loss = 0.522 metric = 78.07%\n",
      "Step 269: loss = 0.521 metric = 78.14%\n",
      "Step 270: loss = 0.518 metric = 78.12%\n",
      "Step 271: loss = 0.517 metric = 78.21%\n",
      "Step 272: loss = 0.515 metric = 78.26%\n",
      "Step 273: loss = 0.512 metric = 78.35%\n",
      "Step 274: loss = 0.511 metric = 78.39%\n",
      "Step 275: loss = 0.509 metric = 78.39%\n",
      "Step 276: loss = 0.507 metric = 78.51%\n",
      "Step 277: loss = 0.506 metric = 78.57%\n",
      "Step 278: loss = 0.503 metric = 78.69%\n",
      "Step 279: loss = 0.501 metric = 78.92%\n",
      "Step 280: loss = 0.5 metric = 78.98%\n",
      "Step 281: loss = 0.497 metric = 79.12%\n",
      "Step 282: loss = 0.496 metric = 79.12%\n",
      "Step 283: loss = 0.494 metric = 79.28%\n",
      "Step 284: loss = 0.492 metric = 79.33%\n",
      "Step 285: loss = 0.49 metric = 79.44%\n",
      "Step 286: loss = 0.488 metric = 79.51%\n",
      "Step 287: loss = 0.486 metric = 79.71%\n",
      "Step 288: loss = 0.484 metric = 79.80%\n",
      "Step 289: loss = 0.483 metric = 79.90%\n",
      "Step 290: loss = 0.481 metric = 79.94%\n",
      "Step 291: loss = 0.479 metric = 80.19%\n",
      "Step 292: loss = 0.477 metric = 80.33%\n",
      "Step 293: loss = 0.475 metric = 80.35%\n",
      "Step 294: loss = 0.473 metric = 80.46%\n",
      "Step 295: loss = 0.471 metric = 80.67%\n",
      "Step 296: loss = 0.469 metric = 80.67%\n",
      "Step 297: loss = 0.468 metric = 80.69%\n",
      "Step 298: loss = 0.466 metric = 80.83%\n",
      "Step 299: loss = 0.464 metric = 80.83%\n",
      "Step 300: loss = 0.462 metric = 80.94%\n",
      "Step 301: loss = 0.46 metric = 81.06%\n",
      "Step 302: loss = 0.458 metric = 81.17%\n",
      "Step 303: loss = 0.456 metric = 81.40%\n",
      "Step 304: loss = 0.454 metric = 81.33%\n",
      "Step 305: loss = 0.452 metric = 81.67%\n",
      "Step 306: loss = 0.451 metric = 81.60%\n",
      "Step 307: loss = 0.449 metric = 81.74%\n",
      "Step 308: loss = 0.448 metric = 81.51%\n",
      "Step 309: loss = 0.447 metric = 81.92%\n",
      "Step 310: loss = 0.446 metric = 81.47%\n",
      "Step 311: loss = 0.444 metric = 82.26%\n",
      "Step 312: loss = 0.441 metric = 81.74%\n",
      "Step 313: loss = 0.438 metric = 82.38%\n",
      "Step 314: loss = 0.436 metric = 82.42%\n",
      "Step 315: loss = 0.435 metric = 82.06%\n",
      "Step 316: loss = 0.434 metric = 82.67%\n",
      "Step 317: loss = 0.432 metric = 82.10%\n",
      "Step 318: loss = 0.43 metric = 82.70%\n",
      "Step 319: loss = 0.427 metric = 82.74%\n",
      "Step 320: loss = 0.425 metric = 82.74%\n",
      "Step 321: loss = 0.425 metric = 83.31%\n",
      "Step 322: loss = 0.423 metric = 82.70%\n",
      "Step 323: loss = 0.421 metric = 83.49%\n",
      "Step 324: loss = 0.418 metric = 83.04%\n",
      "Step 325: loss = 0.416 metric = 83.29%\n",
      "Step 326: loss = 0.415 metric = 83.74%\n",
      "Step 327: loss = 0.414 metric = 83.11%\n",
      "Step 328: loss = 0.413 metric = 83.88%\n",
      "Step 329: loss = 0.411 metric = 83.20%\n",
      "Step 330: loss = 0.409 metric = 83.93%\n",
      "Step 331: loss = 0.407 metric = 83.72%\n",
      "Step 332: loss = 0.405 metric = 83.86%\n",
      "Step 333: loss = 0.403 metric = 84.02%\n",
      "Step 334: loss = 0.402 metric = 83.74%\n",
      "Step 335: loss = 0.401 metric = 84.49%\n",
      "Step 336: loss = 0.4 metric = 83.65%\n",
      "Step 337: loss = 0.4 metric = 84.74%\n",
      "Step 338: loss = 0.398 metric = 83.74%\n",
      "Step 339: loss = 0.397 metric = 84.88%\n",
      "Step 340: loss = 0.392 metric = 84.24%\n",
      "Step 341: loss = 0.39 metric = 84.49%\n",
      "Step 342: loss = 0.39 metric = 85.15%\n",
      "Step 343: loss = 0.39 metric = 84.13%\n",
      "Step 344: loss = 0.39 metric = 85.41%\n",
      "Step 345: loss = 0.387 metric = 84.31%\n",
      "Step 346: loss = 0.383 metric = 85.36%\n",
      "Step 347: loss = 0.381 metric = 85.22%\n",
      "Step 348: loss = 0.381 metric = 84.84%\n",
      "Step 349: loss = 0.381 metric = 85.63%\n",
      "Step 350: loss = 0.378 metric = 84.90%\n",
      "Step 351: loss = 0.376 metric = 85.79%\n",
      "Step 352: loss = 0.373 metric = 85.59%\n",
      "Step 353: loss = 0.373 metric = 85.47%\n",
      "Step 354: loss = 0.373 metric = 85.95%\n",
      "Step 355: loss = 0.371 metric = 85.41%\n",
      "Step 356: loss = 0.37 metric = 86.07%\n",
      "Step 357: loss = 0.367 metric = 85.77%\n",
      "Step 358: loss = 0.365 metric = 86.00%\n",
      "Step 359: loss = 0.364 metric = 86.25%\n",
      "Step 360: loss = 0.363 metric = 85.95%\n",
      "Step 361: loss = 0.362 metric = 86.50%\n",
      "Step 362: loss = 0.36 metric = 86.11%\n",
      "Step 363: loss = 0.358 metric = 86.48%\n",
      "Step 364: loss = 0.356 metric = 86.52%\n",
      "Step 365: loss = 0.355 metric = 86.61%\n",
      "Step 366: loss = 0.354 metric = 86.82%\n",
      "Step 367: loss = 0.353 metric = 86.43%\n",
      "Step 368: loss = 0.354 metric = 86.91%\n",
      "Step 369: loss = 0.354 metric = 86.11%\n",
      "Step 370: loss = 0.358 metric = 87.00%\n",
      "Step 371: loss = 0.354 metric = 85.84%\n",
      "Step 372: loss = 0.353 metric = 87.16%\n",
      "Step 373: loss = 0.344 metric = 87.00%\n",
      "Step 374: loss = 0.349 metric = 86.16%\n",
      "Step 375: loss = 0.36 metric = 86.75%\n",
      "Step 376: loss = 0.342 metric = 87.02%\n",
      "Step 377: loss = 0.349 metric = 85.79%\n",
      "Step 378: loss = 0.369 metric = 86.34%\n",
      "Step 379: loss = 0.337 metric = 87.50%\n",
      "Step 380: loss = 0.382 metric = 84.06%\n",
      "Step 381: loss = 0.497 metric = 79.62%\n",
      "Step 382: loss = 0.505 metric = 79.17%\n",
      "Step 383: loss = 0.357 metric = 86.45%\n",
      "Step 384: loss = 0.53 metric = 80.15%\n",
      "Step 385: loss = 0.379 metric = 84.59%\n",
      "Step 386: loss = 0.415 metric = 84.22%\n",
      "Step 387: loss = 0.465 metric = 82.22%\n",
      "Step 388: loss = 0.42 metric = 84.24%\n",
      "Step 389: loss = 0.365 metric = 85.77%\n",
      "Step 390: loss = 0.419 metric = 82.92%\n",
      "Step 391: loss = 0.391 metric = 83.83%\n",
      "Step 392: loss = 0.354 metric = 86.27%\n",
      "Step 393: loss = 0.392 metric = 85.00%\n",
      "Step 394: loss = 0.391 metric = 84.90%\n",
      "Step 395: loss = 0.352 metric = 85.91%\n",
      "Step 396: loss = 0.363 metric = 85.18%\n",
      "Step 397: loss = 0.376 metric = 84.47%\n",
      "Step 398: loss = 0.342 metric = 86.45%\n",
      "Step 399: loss = 0.351 metric = 86.50%\n",
      "Step 400: loss = 0.361 metric = 86.43%\n",
      "Step 401: loss = 0.344 metric = 87.00%\n",
      "Step 402: loss = 0.337 metric = 87.02%\n",
      "Step 403: loss = 0.351 metric = 85.54%\n",
      "Step 404: loss = 0.343 metric = 86.18%\n",
      "Step 405: loss = 0.333 metric = 87.20%\n",
      "Step 406: loss = 0.34 metric = 87.55%\n",
      "Step 407: loss = 0.34 metric = 87.57%\n",
      "Step 408: loss = 0.33 metric = 87.45%\n",
      "Step 409: loss = 0.329 metric = 87.00%\n",
      "Step 410: loss = 0.335 metric = 86.48%\n",
      "Step 411: loss = 0.327 metric = 87.27%\n",
      "Step 412: loss = 0.326 metric = 87.61%\n",
      "Step 413: loss = 0.33 metric = 87.66%\n",
      "Step 414: loss = 0.326 metric = 87.68%\n",
      "Step 415: loss = 0.322 metric = 87.61%\n",
      "Step 416: loss = 0.325 metric = 86.91%\n",
      "Step 417: loss = 0.323 metric = 87.18%\n",
      "Step 418: loss = 0.319 metric = 88.00%\n",
      "Step 419: loss = 0.321 metric = 88.37%\n",
      "Step 420: loss = 0.32 metric = 88.39%\n",
      "Step 421: loss = 0.317 metric = 88.39%\n",
      "Step 422: loss = 0.317 metric = 87.86%\n",
      "Step 423: loss = 0.317 metric = 87.64%\n",
      "Step 424: loss = 0.315 metric = 88.07%\n",
      "Step 425: loss = 0.314 metric = 88.62%\n",
      "Step 426: loss = 0.314 metric = 88.57%\n",
      "Step 427: loss = 0.312 metric = 88.57%\n",
      "Step 428: loss = 0.311 metric = 88.30%\n",
      "Step 429: loss = 0.312 metric = 88.23%\n",
      "Step 430: loss = 0.31 metric = 88.34%\n",
      "Step 431: loss = 0.309 metric = 88.52%\n",
      "Step 432: loss = 0.309 metric = 88.64%\n",
      "Step 433: loss = 0.308 metric = 88.59%\n",
      "Step 434: loss = 0.307 metric = 88.46%\n",
      "Step 435: loss = 0.307 metric = 88.48%\n",
      "Step 436: loss = 0.305 metric = 88.50%\n",
      "Step 437: loss = 0.305 metric = 88.96%\n",
      "Step 438: loss = 0.305 metric = 89.00%\n",
      "Step 439: loss = 0.303 metric = 88.96%\n",
      "Step 440: loss = 0.303 metric = 88.62%\n",
      "Step 441: loss = 0.302 metric = 88.78%\n",
      "Step 442: loss = 0.301 metric = 88.73%\n",
      "Step 443: loss = 0.301 metric = 89.14%\n",
      "Step 444: loss = 0.3 metric = 89.21%\n",
      "Step 445: loss = 0.299 metric = 89.12%\n",
      "Step 446: loss = 0.298 metric = 88.91%\n",
      "Step 447: loss = 0.298 metric = 88.93%\n",
      "Step 448: loss = 0.297 metric = 89.28%\n",
      "Step 449: loss = 0.296 metric = 89.41%\n",
      "Step 450: loss = 0.296 metric = 89.48%\n",
      "Step 451: loss = 0.295 metric = 89.21%\n",
      "Step 452: loss = 0.294 metric = 89.23%\n",
      "Step 453: loss = 0.293 metric = 89.32%\n",
      "Step 454: loss = 0.293 metric = 89.59%\n",
      "Step 455: loss = 0.292 metric = 89.62%\n",
      "Step 456: loss = 0.291 metric = 89.57%\n",
      "Step 457: loss = 0.291 metric = 89.41%\n",
      "Step 458: loss = 0.29 metric = 89.55%\n",
      "Step 459: loss = 0.289 metric = 89.57%\n",
      "Step 460: loss = 0.289 metric = 89.69%\n",
      "Step 461: loss = 0.288 metric = 89.57%\n",
      "Step 462: loss = 0.287 metric = 89.55%\n",
      "Step 463: loss = 0.287 metric = 89.57%\n",
      "Step 464: loss = 0.286 metric = 89.64%\n",
      "Step 465: loss = 0.285 metric = 89.71%\n",
      "Step 466: loss = 0.285 metric = 89.75%\n",
      "Step 467: loss = 0.284 metric = 89.73%\n",
      "Step 468: loss = 0.283 metric = 89.75%\n",
      "Step 469: loss = 0.283 metric = 89.80%\n",
      "Step 470: loss = 0.282 metric = 89.94%\n",
      "Step 471: loss = 0.281 metric = 89.91%\n",
      "Step 472: loss = 0.281 metric = 89.91%\n",
      "Step 473: loss = 0.28 metric = 89.94%\n",
      "Step 474: loss = 0.279 metric = 89.96%\n",
      "Step 475: loss = 0.279 metric = 90.10%\n",
      "Step 476: loss = 0.278 metric = 90.07%\n",
      "Step 477: loss = 0.277 metric = 90.16%\n",
      "Step 478: loss = 0.277 metric = 90.19%\n",
      "Step 479: loss = 0.276 metric = 90.19%\n",
      "Step 480: loss = 0.275 metric = 90.23%\n",
      "Step 481: loss = 0.275 metric = 90.26%\n",
      "Step 482: loss = 0.274 metric = 90.26%\n",
      "Step 483: loss = 0.273 metric = 90.30%\n",
      "Step 484: loss = 0.273 metric = 90.30%\n",
      "Step 485: loss = 0.272 metric = 90.30%\n",
      "Step 486: loss = 0.271 metric = 90.28%\n",
      "Step 487: loss = 0.271 metric = 90.30%\n",
      "Step 488: loss = 0.27 metric = 90.35%\n",
      "Step 489: loss = 0.269 metric = 90.39%\n",
      "Step 490: loss = 0.269 metric = 90.44%\n",
      "Step 491: loss = 0.268 metric = 90.48%\n",
      "Step 492: loss = 0.267 metric = 90.53%\n",
      "Step 493: loss = 0.267 metric = 90.60%\n",
      "Step 494: loss = 0.266 metric = 90.60%\n",
      "Step 495: loss = 0.265 metric = 90.57%\n",
      "Step 496: loss = 0.265 metric = 90.57%\n",
      "Step 497: loss = 0.264 metric = 90.60%\n",
      "Step 498: loss = 0.263 metric = 90.62%\n",
      "Step 499: loss = 0.263 metric = 90.64%\n",
      "Step 500: loss = 0.262 metric = 90.71%\n",
      "Step 501: loss = 0.261 metric = 90.69%\n",
      "Step 502: loss = 0.261 metric = 90.73%\n",
      "Step 503: loss = 0.26 metric = 90.76%\n",
      "Step 504: loss = 0.259 metric = 90.80%\n",
      "Step 505: loss = 0.259 metric = 90.82%\n",
      "Step 506: loss = 0.258 metric = 90.87%\n",
      "Step 507: loss = 0.258 metric = 90.89%\n",
      "Step 508: loss = 0.257 metric = 90.92%\n",
      "Step 509: loss = 0.256 metric = 90.94%\n",
      "Step 510: loss = 0.256 metric = 90.96%\n",
      "Step 511: loss = 0.255 metric = 91.03%\n",
      "Step 512: loss = 0.255 metric = 91.17%\n",
      "Step 513: loss = 0.254 metric = 91.17%\n",
      "Step 514: loss = 0.253 metric = 91.21%\n",
      "Step 515: loss = 0.253 metric = 91.23%\n",
      "Step 516: loss = 0.252 metric = 91.28%\n",
      "Step 517: loss = 0.251 metric = 91.30%\n",
      "Step 518: loss = 0.251 metric = 91.33%\n",
      "Step 519: loss = 0.25 metric = 91.33%\n",
      "Step 520: loss = 0.25 metric = 91.33%\n",
      "Step 521: loss = 0.249 metric = 91.37%\n",
      "Step 522: loss = 0.248 metric = 91.39%\n",
      "Step 523: loss = 0.248 metric = 91.42%\n",
      "Step 524: loss = 0.247 metric = 91.48%\n",
      "Step 525: loss = 0.247 metric = 91.53%\n",
      "Step 526: loss = 0.246 metric = 91.60%\n",
      "Step 527: loss = 0.245 metric = 91.62%\n",
      "Step 528: loss = 0.245 metric = 91.67%\n",
      "Step 529: loss = 0.244 metric = 91.69%\n",
      "Step 530: loss = 0.244 metric = 91.73%\n",
      "Step 531: loss = 0.243 metric = 91.76%\n",
      "Step 532: loss = 0.242 metric = 91.83%\n",
      "Step 533: loss = 0.242 metric = 91.83%\n",
      "Step 534: loss = 0.241 metric = 91.85%\n",
      "Step 535: loss = 0.24 metric = 91.89%\n",
      "Step 536: loss = 0.24 metric = 91.96%\n",
      "Step 537: loss = 0.239 metric = 91.96%\n",
      "Step 538: loss = 0.239 metric = 91.99%\n",
      "Step 539: loss = 0.238 metric = 92.01%\n",
      "Step 540: loss = 0.237 metric = 92.01%\n",
      "Step 541: loss = 0.237 metric = 92.03%\n",
      "Step 542: loss = 0.236 metric = 92.10%\n",
      "Step 543: loss = 0.236 metric = 92.17%\n",
      "Step 544: loss = 0.235 metric = 92.19%\n",
      "Step 545: loss = 0.234 metric = 92.21%\n",
      "Step 546: loss = 0.234 metric = 92.28%\n",
      "Step 547: loss = 0.233 metric = 92.35%\n",
      "Step 548: loss = 0.233 metric = 92.40%\n",
      "Step 549: loss = 0.232 metric = 92.42%\n",
      "Step 550: loss = 0.231 metric = 92.46%\n",
      "Step 551: loss = 0.231 metric = 92.46%\n",
      "Step 552: loss = 0.23 metric = 92.49%\n",
      "Step 553: loss = 0.23 metric = 92.46%\n",
      "Step 554: loss = 0.229 metric = 92.49%\n",
      "Step 555: loss = 0.229 metric = 92.62%\n",
      "Step 556: loss = 0.228 metric = 92.53%\n",
      "Step 557: loss = 0.227 metric = 92.58%\n",
      "Step 558: loss = 0.227 metric = 92.65%\n",
      "Step 559: loss = 0.226 metric = 92.53%\n",
      "Step 560: loss = 0.226 metric = 92.76%\n",
      "Step 561: loss = 0.224 metric = 92.58%\n",
      "Step 562: loss = 0.224 metric = 92.55%\n",
      "Step 563: loss = 0.224 metric = 92.78%\n",
      "Step 564: loss = 0.222 metric = 92.85%\n",
      "Step 565: loss = 0.223 metric = 92.67%\n",
      "Step 566: loss = 0.225 metric = 92.69%\n",
      "Step 567: loss = 0.221 metric = 92.87%\n",
      "Step 568: loss = 0.231 metric = 92.14%\n",
      "Step 569: loss = 0.333 metric = 87.18%\n",
      "Step 570: loss = 0.237 metric = 92.60%\n",
      "Step 571: loss = 0.392 metric = 86.61%\n",
      "Step 572: loss = 0.466 metric = 80.76%\n",
      "Step 573: loss = 0.653 metric = 71.84%\n",
      "Step 574: loss = 0.438 metric = 82.92%\n",
      "Step 575: loss = 0.283 metric = 89.34%\n",
      "Step 576: loss = 0.579 metric = 81.22%\n",
      "Step 577: loss = 0.323 metric = 87.36%\n",
      "Step 578: loss = 0.363 metric = 85.95%\n",
      "Step 579: loss = 0.445 metric = 82.63%\n",
      "Step 580: loss = 0.434 metric = 83.36%\n",
      "Step 581: loss = 0.345 metric = 87.86%\n",
      "Step 582: loss = 0.288 metric = 89.09%\n",
      "Step 583: loss = 0.343 metric = 86.43%\n",
      "Step 584: loss = 0.342 metric = 86.82%\n",
      "Step 585: loss = 0.262 metric = 90.41%\n",
      "Step 586: loss = 0.285 metric = 89.69%\n",
      "Step 587: loss = 0.327 metric = 87.86%\n",
      "Step 588: loss = 0.3 metric = 88.98%\n",
      "Step 589: loss = 0.251 metric = 90.46%\n",
      "Step 590: loss = 0.273 metric = 88.93%\n",
      "Step 591: loss = 0.288 metric = 88.23%\n",
      "Step 592: loss = 0.241 metric = 90.92%\n",
      "Step 593: loss = 0.253 metric = 91.28%\n",
      "Step 594: loss = 0.27 metric = 90.53%\n",
      "Step 595: loss = 0.256 metric = 91.44%\n",
      "Step 596: loss = 0.238 metric = 91.80%\n",
      "Step 597: loss = 0.244 metric = 90.85%\n",
      "Step 598: loss = 0.255 metric = 90.05%\n",
      "Step 599: loss = 0.238 metric = 91.23%\n",
      "Step 600: loss = 0.232 metric = 92.10%\n",
      "Step 601: loss = 0.238 metric = 92.21%\n",
      "Step 602: loss = 0.24 metric = 92.01%\n",
      "Step 603: loss = 0.231 metric = 92.33%\n",
      "Step 604: loss = 0.226 metric = 92.21%\n",
      "Step 605: loss = 0.232 metric = 91.60%\n",
      "Step 606: loss = 0.232 metric = 91.62%\n",
      "Step 607: loss = 0.224 metric = 92.30%\n",
      "Step 608: loss = 0.225 metric = 92.51%\n",
      "Step 609: loss = 0.228 metric = 92.62%\n",
      "Step 610: loss = 0.224 metric = 92.62%\n",
      "Step 611: loss = 0.219 metric = 92.83%\n",
      "Step 612: loss = 0.22 metric = 92.60%\n",
      "Step 613: loss = 0.222 metric = 92.53%\n",
      "Step 614: loss = 0.219 metric = 92.78%\n",
      "Step 615: loss = 0.217 metric = 93.01%\n",
      "Step 616: loss = 0.218 metric = 93.01%\n",
      "Step 617: loss = 0.218 metric = 93.12%\n",
      "Step 618: loss = 0.216 metric = 93.12%\n",
      "Step 619: loss = 0.214 metric = 93.17%\n",
      "Step 620: loss = 0.215 metric = 92.96%\n",
      "Step 621: loss = 0.215 metric = 92.85%\n",
      "Step 622: loss = 0.213 metric = 93.17%\n",
      "Step 623: loss = 0.212 metric = 93.37%\n",
      "Step 624: loss = 0.212 metric = 93.33%\n",
      "Step 625: loss = 0.212 metric = 93.35%\n",
      "Step 626: loss = 0.21 metric = 93.37%\n",
      "Step 627: loss = 0.21 metric = 93.17%\n",
      "Step 628: loss = 0.21 metric = 93.19%\n",
      "Step 629: loss = 0.209 metric = 93.37%\n",
      "Step 630: loss = 0.208 metric = 93.49%\n",
      "Step 631: loss = 0.208 metric = 93.53%\n",
      "Step 632: loss = 0.207 metric = 93.58%\n",
      "Step 633: loss = 0.207 metric = 93.47%\n",
      "Step 634: loss = 0.207 metric = 93.58%\n",
      "Step 635: loss = 0.206 metric = 93.58%\n",
      "Step 636: loss = 0.205 metric = 93.60%\n",
      "Step 637: loss = 0.205 metric = 93.62%\n",
      "Step 638: loss = 0.205 metric = 93.62%\n",
      "Step 639: loss = 0.204 metric = 93.62%\n",
      "Step 640: loss = 0.204 metric = 93.72%\n",
      "Step 641: loss = 0.203 metric = 93.74%\n",
      "Step 642: loss = 0.203 metric = 93.69%\n",
      "Step 643: loss = 0.202 metric = 93.74%\n",
      "Step 644: loss = 0.202 metric = 93.76%\n",
      "Step 645: loss = 0.201 metric = 93.81%\n",
      "Step 646: loss = 0.201 metric = 93.88%\n",
      "Step 647: loss = 0.201 metric = 93.88%\n",
      "Step 648: loss = 0.2 metric = 93.92%\n",
      "Step 649: loss = 0.2 metric = 93.83%\n",
      "Step 650: loss = 0.199 metric = 93.88%\n",
      "Step 651: loss = 0.199 metric = 93.99%\n",
      "Step 652: loss = 0.199 metric = 93.97%\n",
      "Step 653: loss = 0.198 metric = 93.97%\n",
      "Step 654: loss = 0.198 metric = 94.01%\n",
      "Step 655: loss = 0.197 metric = 93.97%\n",
      "Step 656: loss = 0.197 metric = 93.99%\n",
      "Step 657: loss = 0.197 metric = 94.06%\n",
      "Step 658: loss = 0.196 metric = 94.06%\n",
      "Step 659: loss = 0.196 metric = 94.06%\n",
      "Step 660: loss = 0.195 metric = 94.08%\n",
      "Step 661: loss = 0.195 metric = 94.03%\n",
      "Step 662: loss = 0.195 metric = 94.08%\n",
      "Step 663: loss = 0.194 metric = 94.13%\n",
      "Step 664: loss = 0.194 metric = 94.13%\n",
      "Step 665: loss = 0.194 metric = 94.15%\n",
      "Step 666: loss = 0.193 metric = 94.19%\n",
      "Step 667: loss = 0.193 metric = 94.19%\n",
      "Step 668: loss = 0.192 metric = 94.26%\n",
      "Step 669: loss = 0.192 metric = 94.29%\n",
      "Step 670: loss = 0.192 metric = 94.29%\n",
      "Step 671: loss = 0.191 metric = 94.29%\n",
      "Step 672: loss = 0.191 metric = 94.31%\n",
      "Step 673: loss = 0.191 metric = 94.29%\n",
      "Step 674: loss = 0.19 metric = 94.29%\n",
      "Step 675: loss = 0.19 metric = 94.31%\n",
      "Step 676: loss = 0.189 metric = 94.29%\n",
      "Step 677: loss = 0.189 metric = 94.29%\n",
      "Step 678: loss = 0.189 metric = 94.31%\n",
      "Step 679: loss = 0.188 metric = 94.33%\n",
      "Step 680: loss = 0.188 metric = 94.35%\n",
      "Step 681: loss = 0.188 metric = 94.35%\n",
      "Step 682: loss = 0.187 metric = 94.40%\n",
      "Step 683: loss = 0.187 metric = 94.47%\n",
      "Step 684: loss = 0.186 metric = 94.49%\n",
      "Step 685: loss = 0.186 metric = 94.51%\n",
      "Step 686: loss = 0.186 metric = 94.54%\n",
      "Step 687: loss = 0.185 metric = 94.54%\n",
      "Step 688: loss = 0.185 metric = 94.56%\n",
      "Step 689: loss = 0.185 metric = 94.56%\n",
      "Step 690: loss = 0.184 metric = 94.58%\n",
      "Step 691: loss = 0.184 metric = 94.58%\n",
      "Step 692: loss = 0.184 metric = 94.56%\n",
      "Step 693: loss = 0.183 metric = 94.56%\n",
      "Step 694: loss = 0.183 metric = 94.56%\n",
      "Step 695: loss = 0.182 metric = 94.58%\n",
      "Step 696: loss = 0.182 metric = 94.58%\n",
      "Step 697: loss = 0.182 metric = 94.60%\n",
      "Step 698: loss = 0.181 metric = 94.65%\n",
      "Step 699: loss = 0.181 metric = 94.67%\n",
      "Step 700: loss = 0.181 metric = 94.67%\n",
      "Step 701: loss = 0.18 metric = 94.67%\n",
      "Step 702: loss = 0.18 metric = 94.72%\n",
      "Step 703: loss = 0.179 metric = 94.74%\n",
      "Step 704: loss = 0.179 metric = 94.76%\n",
      "Step 705: loss = 0.179 metric = 94.76%\n",
      "Step 706: loss = 0.178 metric = 94.81%\n",
      "Step 707: loss = 0.178 metric = 94.81%\n",
      "Step 708: loss = 0.178 metric = 94.81%\n",
      "Step 709: loss = 0.177 metric = 94.85%\n",
      "Step 710: loss = 0.177 metric = 94.85%\n",
      "Step 711: loss = 0.177 metric = 94.83%\n",
      "Step 712: loss = 0.176 metric = 94.88%\n",
      "Step 713: loss = 0.176 metric = 94.90%\n",
      "Step 714: loss = 0.176 metric = 94.92%\n",
      "Step 715: loss = 0.175 metric = 94.92%\n",
      "Step 716: loss = 0.175 metric = 94.90%\n",
      "Step 717: loss = 0.175 metric = 94.92%\n",
      "Step 718: loss = 0.174 metric = 94.99%\n",
      "Step 719: loss = 0.174 metric = 94.99%\n",
      "Step 720: loss = 0.174 metric = 95.01%\n",
      "Step 721: loss = 0.173 metric = 95.06%\n",
      "Step 722: loss = 0.173 metric = 95.08%\n",
      "Step 723: loss = 0.173 metric = 95.06%\n",
      "Step 724: loss = 0.172 metric = 95.08%\n",
      "Step 725: loss = 0.172 metric = 95.10%\n",
      "Step 726: loss = 0.172 metric = 95.15%\n",
      "Step 727: loss = 0.171 metric = 95.13%\n",
      "Step 728: loss = 0.171 metric = 95.13%\n",
      "Step 729: loss = 0.171 metric = 95.13%\n",
      "Step 730: loss = 0.17 metric = 95.15%\n",
      "Step 731: loss = 0.17 metric = 95.13%\n",
      "Step 732: loss = 0.17 metric = 95.15%\n",
      "Step 733: loss = 0.169 metric = 95.20%\n",
      "Step 734: loss = 0.169 metric = 95.22%\n",
      "Step 735: loss = 0.169 metric = 95.22%\n",
      "Step 736: loss = 0.168 metric = 95.22%\n",
      "Step 737: loss = 0.168 metric = 95.22%\n",
      "Step 738: loss = 0.168 metric = 95.26%\n",
      "Step 739: loss = 0.167 metric = 95.31%\n",
      "Step 740: loss = 0.167 metric = 95.33%\n",
      "Step 741: loss = 0.167 metric = 95.33%\n",
      "Step 742: loss = 0.166 metric = 95.33%\n",
      "Step 743: loss = 0.166 metric = 95.36%\n",
      "Step 744: loss = 0.166 metric = 95.36%\n",
      "Step 745: loss = 0.165 metric = 95.36%\n",
      "Step 746: loss = 0.165 metric = 95.36%\n",
      "Step 747: loss = 0.165 metric = 95.36%\n",
      "Step 748: loss = 0.165 metric = 95.38%\n",
      "Step 749: loss = 0.164 metric = 95.38%\n",
      "Step 750: loss = 0.164 metric = 95.38%\n",
      "Step 751: loss = 0.164 metric = 95.38%\n",
      "Step 752: loss = 0.163 metric = 95.42%\n",
      "Step 753: loss = 0.163 metric = 95.42%\n",
      "Step 754: loss = 0.163 metric = 95.42%\n",
      "Step 755: loss = 0.162 metric = 95.42%\n",
      "Step 756: loss = 0.162 metric = 95.42%\n",
      "Step 757: loss = 0.162 metric = 95.45%\n",
      "Step 758: loss = 0.161 metric = 95.45%\n",
      "Step 759: loss = 0.161 metric = 95.49%\n",
      "Step 760: loss = 0.161 metric = 95.56%\n",
      "Step 761: loss = 0.161 metric = 95.61%\n",
      "Step 762: loss = 0.16 metric = 95.58%\n",
      "Step 763: loss = 0.16 metric = 95.58%\n",
      "Step 764: loss = 0.16 metric = 95.61%\n",
      "Step 765: loss = 0.159 metric = 95.61%\n",
      "Step 766: loss = 0.159 metric = 95.61%\n",
      "Step 767: loss = 0.159 metric = 95.61%\n",
      "Step 768: loss = 0.158 metric = 95.61%\n",
      "Step 769: loss = 0.158 metric = 95.61%\n",
      "Step 770: loss = 0.158 metric = 95.65%\n",
      "Step 771: loss = 0.157 metric = 95.65%\n",
      "Step 772: loss = 0.157 metric = 95.67%\n",
      "Step 773: loss = 0.157 metric = 95.67%\n",
      "Step 774: loss = 0.157 metric = 95.67%\n",
      "Step 775: loss = 0.156 metric = 95.67%\n",
      "Step 776: loss = 0.156 metric = 95.70%\n",
      "Step 777: loss = 0.156 metric = 95.67%\n",
      "Step 778: loss = 0.155 metric = 95.70%\n",
      "Step 779: loss = 0.155 metric = 95.74%\n",
      "Step 780: loss = 0.155 metric = 95.72%\n",
      "Step 781: loss = 0.155 metric = 95.77%\n",
      "Step 782: loss = 0.154 metric = 95.77%\n",
      "Step 783: loss = 0.154 metric = 95.79%\n",
      "Step 784: loss = 0.154 metric = 95.77%\n",
      "Step 785: loss = 0.153 metric = 95.79%\n",
      "Step 786: loss = 0.153 metric = 95.77%\n",
      "Step 787: loss = 0.153 metric = 95.81%\n",
      "Step 788: loss = 0.152 metric = 95.79%\n",
      "Step 789: loss = 0.152 metric = 95.81%\n",
      "Step 790: loss = 0.152 metric = 95.81%\n",
      "Step 791: loss = 0.152 metric = 95.81%\n",
      "Step 792: loss = 0.151 metric = 95.86%\n",
      "Step 793: loss = 0.151 metric = 95.86%\n",
      "Step 794: loss = 0.151 metric = 95.88%\n",
      "Step 795: loss = 0.15 metric = 95.92%\n",
      "Step 796: loss = 0.15 metric = 95.90%\n",
      "Step 797: loss = 0.15 metric = 95.95%\n",
      "Step 798: loss = 0.149 metric = 95.95%\n",
      "Step 799: loss = 0.149 metric = 95.95%\n",
      "Step 800: loss = 0.149 metric = 95.99%\n",
      "Step 801: loss = 0.148 metric = 95.99%\n",
      "Step 802: loss = 0.148 metric = 96.02%\n",
      "Step 803: loss = 0.148 metric = 96.06%\n",
      "Step 804: loss = 0.148 metric = 96.06%\n",
      "Step 805: loss = 0.147 metric = 96.06%\n",
      "Step 806: loss = 0.147 metric = 96.04%\n",
      "Step 807: loss = 0.147 metric = 96.06%\n",
      "Step 808: loss = 0.146 metric = 96.06%\n",
      "Step 809: loss = 0.146 metric = 96.11%\n",
      "Step 810: loss = 0.146 metric = 96.11%\n",
      "Step 811: loss = 0.146 metric = 96.06%\n",
      "Step 812: loss = 0.145 metric = 96.13%\n",
      "Step 813: loss = 0.145 metric = 96.15%\n",
      "Step 814: loss = 0.145 metric = 96.17%\n",
      "Step 815: loss = 0.144 metric = 96.15%\n",
      "Step 816: loss = 0.144 metric = 96.17%\n",
      "Step 817: loss = 0.144 metric = 96.17%\n",
      "Step 818: loss = 0.144 metric = 96.20%\n",
      "Step 819: loss = 0.143 metric = 96.20%\n",
      "Step 820: loss = 0.143 metric = 96.20%\n",
      "Step 821: loss = 0.143 metric = 96.20%\n",
      "Step 822: loss = 0.142 metric = 96.20%\n",
      "Step 823: loss = 0.142 metric = 96.17%\n",
      "Step 824: loss = 0.142 metric = 96.22%\n",
      "Step 825: loss = 0.142 metric = 96.20%\n",
      "Step 826: loss = 0.141 metric = 96.24%\n",
      "Step 827: loss = 0.141 metric = 96.31%\n",
      "Step 828: loss = 0.141 metric = 96.31%\n",
      "Step 829: loss = 0.141 metric = 96.31%\n",
      "Step 830: loss = 0.14 metric = 96.36%\n",
      "Step 831: loss = 0.14 metric = 96.38%\n",
      "Step 832: loss = 0.14 metric = 96.38%\n",
      "Step 833: loss = 0.139 metric = 96.38%\n",
      "Step 834: loss = 0.139 metric = 96.38%\n",
      "Step 835: loss = 0.139 metric = 96.38%\n",
      "Step 836: loss = 0.139 metric = 96.38%\n",
      "Step 837: loss = 0.138 metric = 96.38%\n",
      "Step 838: loss = 0.138 metric = 96.40%\n",
      "Step 839: loss = 0.138 metric = 96.43%\n",
      "Step 840: loss = 0.138 metric = 96.43%\n",
      "Step 841: loss = 0.137 metric = 96.43%\n",
      "Step 842: loss = 0.137 metric = 96.43%\n",
      "Step 843: loss = 0.137 metric = 96.45%\n",
      "Step 844: loss = 0.137 metric = 96.45%\n",
      "Step 845: loss = 0.136 metric = 96.45%\n",
      "Step 846: loss = 0.136 metric = 96.45%\n",
      "Step 847: loss = 0.136 metric = 96.45%\n",
      "Step 848: loss = 0.136 metric = 96.45%\n",
      "Step 849: loss = 0.135 metric = 96.43%\n",
      "Step 850: loss = 0.135 metric = 96.43%\n",
      "Step 851: loss = 0.135 metric = 96.47%\n",
      "Step 852: loss = 0.135 metric = 96.43%\n",
      "Step 853: loss = 0.134 metric = 96.47%\n",
      "Step 854: loss = 0.134 metric = 96.47%\n",
      "Step 855: loss = 0.134 metric = 96.49%\n",
      "Step 856: loss = 0.134 metric = 96.52%\n",
      "Step 857: loss = 0.133 metric = 96.49%\n",
      "Step 858: loss = 0.133 metric = 96.56%\n",
      "Step 859: loss = 0.133 metric = 96.54%\n",
      "Step 860: loss = 0.133 metric = 96.56%\n",
      "Step 861: loss = 0.132 metric = 96.56%\n",
      "Step 862: loss = 0.132 metric = 96.58%\n",
      "Step 863: loss = 0.132 metric = 96.58%\n",
      "Step 864: loss = 0.132 metric = 96.58%\n",
      "Step 865: loss = 0.131 metric = 96.63%\n",
      "Step 866: loss = 0.131 metric = 96.58%\n",
      "Step 867: loss = 0.131 metric = 96.61%\n",
      "Step 868: loss = 0.131 metric = 96.63%\n",
      "Step 869: loss = 0.13 metric = 96.65%\n",
      "Step 870: loss = 0.13 metric = 96.65%\n",
      "Step 871: loss = 0.13 metric = 96.65%\n",
      "Step 872: loss = 0.13 metric = 96.68%\n",
      "Step 873: loss = 0.129 metric = 96.70%\n",
      "Step 874: loss = 0.129 metric = 96.70%\n",
      "Step 875: loss = 0.129 metric = 96.70%\n",
      "Step 876: loss = 0.129 metric = 96.70%\n",
      "Step 877: loss = 0.128 metric = 96.70%\n",
      "Step 878: loss = 0.128 metric = 96.70%\n",
      "Step 879: loss = 0.128 metric = 96.77%\n",
      "Step 880: loss = 0.128 metric = 96.70%\n",
      "Step 881: loss = 0.128 metric = 96.74%\n",
      "Step 882: loss = 0.127 metric = 96.74%\n",
      "Step 883: loss = 0.127 metric = 96.77%\n",
      "Step 884: loss = 0.127 metric = 96.77%\n",
      "Step 885: loss = 0.127 metric = 96.72%\n",
      "Step 886: loss = 0.127 metric = 96.74%\n",
      "Step 887: loss = 0.126 metric = 96.74%\n",
      "Step 888: loss = 0.126 metric = 96.77%\n",
      "Step 889: loss = 0.126 metric = 96.77%\n",
      "Step 890: loss = 0.125 metric = 96.77%\n",
      "Step 891: loss = 0.125 metric = 96.79%\n",
      "Step 892: loss = 0.125 metric = 96.77%\n",
      "Step 893: loss = 0.125 metric = 96.79%\n",
      "Step 894: loss = 0.124 metric = 96.81%\n",
      "Step 895: loss = 0.124 metric = 96.84%\n",
      "Step 896: loss = 0.124 metric = 96.86%\n",
      "Step 897: loss = 0.124 metric = 96.81%\n",
      "Step 898: loss = 0.124 metric = 96.79%\n",
      "Step 899: loss = 0.123 metric = 96.86%\n",
      "Step 900: loss = 0.123 metric = 96.86%\n",
      "Step 901: loss = 0.123 metric = 96.81%\n",
      "Step 902: loss = 0.123 metric = 96.86%\n",
      "Step 903: loss = 0.122 metric = 96.88%\n",
      "Step 904: loss = 0.122 metric = 96.88%\n",
      "Step 905: loss = 0.122 metric = 96.86%\n",
      "Step 906: loss = 0.122 metric = 96.86%\n",
      "Step 907: loss = 0.121 metric = 96.88%\n",
      "Step 908: loss = 0.121 metric = 96.90%\n",
      "Step 909: loss = 0.121 metric = 96.88%\n",
      "Step 910: loss = 0.121 metric = 96.90%\n",
      "Step 911: loss = 0.12 metric = 96.90%\n",
      "Step 912: loss = 0.12 metric = 96.88%\n",
      "Step 913: loss = 0.12 metric = 96.95%\n",
      "Step 914: loss = 0.12 metric = 96.95%\n",
      "Step 915: loss = 0.12 metric = 96.99%\n",
      "Step 916: loss = 0.119 metric = 96.99%\n",
      "Step 917: loss = 0.119 metric = 96.99%\n",
      "Step 918: loss = 0.119 metric = 97.02%\n",
      "Step 919: loss = 0.119 metric = 97.04%\n",
      "Step 920: loss = 0.118 metric = 97.02%\n",
      "Step 921: loss = 0.118 metric = 97.04%\n",
      "Step 922: loss = 0.118 metric = 97.02%\n",
      "Step 923: loss = 0.118 metric = 96.97%\n",
      "Step 924: loss = 0.118 metric = 96.99%\n",
      "Step 925: loss = 0.117 metric = 97.02%\n",
      "Step 926: loss = 0.117 metric = 97.04%\n",
      "Step 927: loss = 0.117 metric = 97.04%\n",
      "Step 928: loss = 0.117 metric = 96.99%\n",
      "Step 929: loss = 0.116 metric = 97.04%\n",
      "Step 930: loss = 0.116 metric = 97.02%\n",
      "Step 931: loss = 0.116 metric = 97.04%\n",
      "Step 932: loss = 0.116 metric = 97.04%\n",
      "Step 933: loss = 0.116 metric = 96.99%\n",
      "Step 934: loss = 0.115 metric = 96.99%\n",
      "Step 935: loss = 0.115 metric = 97.04%\n",
      "Step 936: loss = 0.115 metric = 97.06%\n",
      "Step 937: loss = 0.115 metric = 97.02%\n",
      "Step 938: loss = 0.115 metric = 97.04%\n",
      "Step 939: loss = 0.114 metric = 97.04%\n",
      "Step 940: loss = 0.114 metric = 97.02%\n",
      "Step 941: loss = 0.114 metric = 97.02%\n",
      "Step 942: loss = 0.113 metric = 97.06%\n",
      "Step 943: loss = 0.113 metric = 97.09%\n",
      "Step 944: loss = 0.113 metric = 97.06%\n",
      "Step 945: loss = 0.113 metric = 97.09%\n",
      "Step 946: loss = 0.129 metric = 96.63%\n",
      "Step 947: loss = 0.697 metric = 76.00%\n",
      "Step 948: loss = 0.343 metric = 87.66%\n",
      "Step 949: loss = 0.344 metric = 91.42%\n",
      "Step 950: loss = 0.212 metric = 92.60%\n",
      "Step 951: loss = 0.319 metric = 87.86%\n",
      "Step 952: loss = 0.281 metric = 89.25%\n",
      "Step 953: loss = 0.222 metric = 91.89%\n",
      "Step 954: loss = 0.304 metric = 89.64%\n",
      "Step 955: loss = 0.196 metric = 93.58%\n",
      "Step 956: loss = 0.236 metric = 92.24%\n",
      "Step 957: loss = 0.239 metric = 91.87%\n",
      "Step 958: loss = 0.178 metric = 94.58%\n",
      "Step 959: loss = 0.196 metric = 93.72%\n",
      "Step 960: loss = 0.172 metric = 94.47%\n",
      "Step 961: loss = 0.162 metric = 95.04%\n",
      "Step 962: loss = 0.18 metric = 94.49%\n",
      "Step 963: loss = 0.159 metric = 95.54%\n",
      "Step 964: loss = 0.148 metric = 95.54%\n",
      "Step 965: loss = 0.174 metric = 94.58%\n",
      "Step 966: loss = 0.143 metric = 96.08%\n",
      "Step 967: loss = 0.167 metric = 94.74%\n",
      "Step 968: loss = 0.16 metric = 95.20%\n",
      "Step 969: loss = 0.138 metric = 95.99%\n",
      "Step 970: loss = 0.16 metric = 95.13%\n",
      "Step 971: loss = 0.142 metric = 95.77%\n",
      "Step 972: loss = 0.137 metric = 96.13%\n",
      "Step 973: loss = 0.145 metric = 96.02%\n",
      "Step 974: loss = 0.138 metric = 96.24%\n",
      "Step 975: loss = 0.129 metric = 96.56%\n",
      "Step 976: loss = 0.132 metric = 96.15%\n",
      "Step 977: loss = 0.132 metric = 96.20%\n",
      "Step 978: loss = 0.124 metric = 96.74%\n",
      "Step 979: loss = 0.127 metric = 96.72%\n",
      "Step 980: loss = 0.129 metric = 96.74%\n",
      "Step 981: loss = 0.125 metric = 96.74%\n",
      "Step 982: loss = 0.122 metric = 96.88%\n",
      "Step 983: loss = 0.126 metric = 96.47%\n",
      "Step 984: loss = 0.122 metric = 96.79%\n",
      "Step 985: loss = 0.121 metric = 96.95%\n",
      "Step 986: loss = 0.122 metric = 96.90%\n",
      "Step 987: loss = 0.121 metric = 96.99%\n",
      "Step 988: loss = 0.118 metric = 97.06%\n",
      "Step 989: loss = 0.119 metric = 96.99%\n",
      "Step 990: loss = 0.119 metric = 96.99%\n",
      "Step 991: loss = 0.117 metric = 97.06%\n",
      "Step 992: loss = 0.117 metric = 97.06%\n",
      "Step 993: loss = 0.117 metric = 97.09%\n",
      "Step 994: loss = 0.116 metric = 97.02%\n",
      "Step 995: loss = 0.115 metric = 97.09%\n",
      "Step 996: loss = 0.116 metric = 97.04%\n",
      "Step 997: loss = 0.115 metric = 97.11%\n",
      "Step 998: loss = 0.114 metric = 97.15%\n",
      "Step 999: loss = 0.114 metric = 97.13%\n"
     ]
    }
   ],
   "source": [
    "model = RNN(len(labels), tokenizer, 100, 100)\n",
    "model.to(\"cuda:0\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.0E-4)\n",
    "train = Batchifyer(df_train, tokenizer, n_batches=1, batch_size=None)\n",
    "val = Batchifyer(df_val, tokenizer, n_batches=1, batch_size=None)\n",
    "train_loop(model, optimizer, train, val, n_steps=1000, patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 97.222%\n"
     ]
    }
   ],
   "source": [
    "X, Y = data_to_tensor(df_test, tokenizer)\n",
    "y_pred = model.predict(X)\n",
    "acc = accuracy(y_pred, Y.to(y_pred.device))\n",
    "print(f\"accuracy {acc:.3%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice II\n",
    "\n",
    "Programmer un modèle type encodeur de transformeur pour classifier les tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, projection_dim: int, n_heads: int, activation: Callable):\n",
    "        super().__init__()\n",
    "        self.projection_dim = projection_dim\n",
    "        self.n_heads = n_heads\n",
    "        D = projection_dim * n_heads\n",
    "        self.q = torch.nn.Linear(D, D, bias=False)\n",
    "        self.k = torch.nn.Linear(D, D, bias=False)\n",
    "        self.v = torch.nn.Linear(D, D, bias=False)\n",
    "        self.intermediate_norm = torch.nn.LayerNorm(D)\n",
    "        self.expand = torch.nn.Linear(D, 4*D)\n",
    "        self.activation = activation\n",
    "        self.contract = torch.nn.Linear(4*D, D)\n",
    "        self.out_norm = torch.nn.LayerNorm(D)\n",
    "    \n",
    "    def forward(self, X: torch.Tensor, mask: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : torch.Tensor\n",
    "            tensor of shape (N, L, D)\n",
    "        mask : torch.Tensor\n",
    "            tensor of boooleans of shape (N, L, L)\n",
    "        \"\"\"\n",
    "        input = X\n",
    "        N, L, D = X.shape\n",
    "        X = X.reshape(-1, D)\n",
    "        Q = self.q(X)\n",
    "        Q = Q.reshape(N, L, self.n_heads, self.projection_dim).permute(0, 2, 1, 3)\n",
    "        K = self.k(X).reshape(N, L, self.n_heads, self.projection_dim).permute(0, 2, 1, 3)\n",
    "        V = self.v(X).reshape(N, L, self.n_heads, self.projection_dim).permute(0, 2, 1, 3)\n",
    "        S = torch.einsum(\"nhld, nhkd -> nhlk\", Q, K)\n",
    "        S = torch.masked_fill(S, mask.unsqueeze(1), -float(\"inf\"))\n",
    "        S = torch.softmax(S, dim=-1)\n",
    "        S = torch.masked_fill(S, mask.unsqueeze(1), 0)\n",
    "        X = (S @ V).permute(0, 2, 1, 3).reshape(N, L, D)\n",
    "        X = self.intermediate_norm((X + input).reshape(-1, D)).reshape(N, L, D)\n",
    "        intermediate = X\n",
    "        X = self.expand(X)\n",
    "        X = self.activation(X)\n",
    "        X = self.contract(X)\n",
    "        X = self.out_norm((X + intermediate).reshape(-1, D)).reshape(N, L, D)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes: int, tokenizer: Tokenizer, n_stages: int, projection_dim: int, n_heads: int, activation: Callable = torch.relu):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.embedding = torch.nn.Embedding(len(tokenizer.vocabulary), n_heads*projection_dim)\n",
    "        self.stages = torch.nn.ModuleList()\n",
    "        for _ in range(n_stages):\n",
    "            self.stages.append(AttentionBlock(projection_dim, n_heads, activation))\n",
    "        self.output = torch.nn.Linear(projection_dim * n_heads, n_classes)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : torch.Tensor\n",
    "            tensor of shape (N, L)\n",
    "        \"\"\"\n",
    "        X = X.to(self.device)\n",
    "        mask = (X == self.tokenizer.PAD)\n",
    "        mask = (mask.unsqueeze(1) | mask.unsqueeze(2))\n",
    "        X = self.embedding(X)\n",
    "        for stage in self.stages:\n",
    "            if self.training:\n",
    "                X = checkpoint(stage, X, mask)\n",
    "            else:\n",
    "                X = stage(X, mask)\n",
    "        return self.output(X.mean(dim=1))\n",
    "    \n",
    "    def predict(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            Y = self(X)\n",
    "        return Y.max(dim=1).indices\n",
    "    \n",
    "    def loss(self, X: torch.Tensor, Y: torch.Tensor) -> torch.Tensor:\n",
    "        y_pred = self(X)\n",
    "        return F.cross_entropy(y_pred, Y.to(y_pred.device))\n",
    "\n",
    "    def metric(self, X: torch.Tensor, Y: torch.Tensor) -> torch.Tensor:\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy(y_pred, Y.to(y_pred.device))\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return self.output.weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 1.19 metric = 17.12%\n",
      "Step 1: loss = 1.46 metric = 62.25%\n",
      "Step 2: loss = 1.34 metric = 62.25%\n",
      "Step 3: loss = 1.11 metric = 62.25%\n",
      "Step 4: loss = 1.06 metric = 62.32%\n",
      "Step 5: loss = 0.974 metric = 63.71%\n",
      "Step 6: loss = 0.909 metric = 62.25%\n",
      "Step 7: loss = 0.938 metric = 62.25%\n",
      "Step 8: loss = 0.959 metric = 62.25%\n",
      "Step 9: loss = 0.942 metric = 62.25%\n",
      "Step 10: loss = 0.914 metric = 62.25%\n",
      "Step 11: loss = 0.891 metric = 62.25%\n",
      "Step 12: loss = 0.875 metric = 62.25%\n",
      "Step 13: loss = 0.868 metric = 62.25%\n",
      "Step 14: loss = 0.871 metric = 63.37%\n",
      "Step 15: loss = 0.876 metric = 63.68%\n",
      "Step 16: loss = 0.877 metric = 63.84%\n",
      "Step 17: loss = 0.868 metric = 63.93%\n",
      "Step 18: loss = 0.853 metric = 63.64%\n",
      "Step 19: loss = 0.838 metric = 63.78%\n",
      "Step 20: loss = 0.827 metric = 63.46%\n",
      "Step 21: loss = 0.82 metric = 63.55%\n",
      "Step 22: loss = 0.815 metric = 63.68%\n",
      "Step 23: loss = 0.81 metric = 65.05%\n",
      "Step 24: loss = 0.804 metric = 66.07%\n",
      "Step 25: loss = 0.797 metric = 67.40%\n",
      "Step 26: loss = 0.787 metric = 68.72%\n",
      "Step 27: loss = 0.776 metric = 68.90%\n",
      "Step 28: loss = 0.765 metric = 68.85%\n",
      "Step 29: loss = 0.756 metric = 68.74%\n",
      "Step 30: loss = 0.748 metric = 68.53%\n",
      "Step 31: loss = 0.741 metric = 69.03%\n",
      "Step 32: loss = 0.732 metric = 69.76%\n",
      "Step 33: loss = 0.719 metric = 71.31%\n",
      "Step 34: loss = 0.707 metric = 72.38%\n",
      "Step 35: loss = 0.695 metric = 73.57%\n",
      "Step 36: loss = 0.683 metric = 74.13%\n",
      "Step 37: loss = 0.672 metric = 74.75%\n",
      "Step 38: loss = 0.661 metric = 75.14%\n",
      "Step 39: loss = 0.648 metric = 75.93%\n",
      "Step 40: loss = 0.636 metric = 76.71%\n",
      "Step 41: loss = 0.621 metric = 77.16%\n",
      "Step 42: loss = 0.607 metric = 77.55%\n",
      "Step 43: loss = 0.592 metric = 77.80%\n",
      "Step 44: loss = 0.578 metric = 78.62%\n",
      "Step 45: loss = 0.563 metric = 79.58%\n",
      "Step 46: loss = 0.546 metric = 80.97%\n",
      "Step 47: loss = 0.529 metric = 82.15%\n",
      "Step 48: loss = 0.513 metric = 82.76%\n",
      "Step 49: loss = 0.495 metric = 83.90%\n",
      "Step 50: loss = 0.478 metric = 84.36%\n",
      "Step 51: loss = 0.462 metric = 85.13%\n",
      "Step 52: loss = 0.454 metric = 85.22%\n",
      "Step 53: loss = 0.431 metric = 86.61%\n",
      "Step 54: loss = 0.404 metric = 87.96%\n",
      "Step 55: loss = 0.383 metric = 89.30%\n",
      "Step 56: loss = 0.374 metric = 89.71%\n",
      "Step 57: loss = 0.362 metric = 89.66%\n",
      "Step 58: loss = 0.333 metric = 91.33%\n",
      "Step 59: loss = 0.324 metric = 91.60%\n",
      "Step 60: loss = 0.313 metric = 91.92%\n",
      "Step 61: loss = 0.288 metric = 93.12%\n",
      "Step 62: loss = 0.286 metric = 93.33%\n",
      "Step 63: loss = 0.266 metric = 94.01%\n",
      "Step 64: loss = 0.255 metric = 94.42%\n",
      "Step 65: loss = 0.242 metric = 95.13%\n",
      "Step 66: loss = 0.236 metric = 95.31%\n",
      "Step 67: loss = 0.223 metric = 95.77%\n",
      "Step 68: loss = 0.222 metric = 95.74%\n",
      "Step 69: loss = 0.206 metric = 96.27%\n",
      "Step 70: loss = 0.208 metric = 96.24%\n",
      "Step 71: loss = 0.2 metric = 96.47%\n",
      "Step 72: loss = 0.192 metric = 96.74%\n",
      "Step 73: loss = 0.189 metric = 96.81%\n",
      "Step 74: loss = 0.184 metric = 96.97%\n",
      "Step 75: loss = 0.179 metric = 97.20%\n",
      "Step 76: loss = 0.176 metric = 97.27%\n",
      "Step 77: loss = 0.171 metric = 97.38%\n",
      "Step 78: loss = 0.168 metric = 97.54%\n",
      "Step 79: loss = 0.165 metric = 97.70%\n",
      "Step 80: loss = 0.161 metric = 97.77%\n",
      "Step 81: loss = 0.158 metric = 97.86%\n",
      "Step 82: loss = 0.155 metric = 97.95%\n",
      "Step 83: loss = 0.152 metric = 98.09%\n",
      "Step 84: loss = 0.148 metric = 98.18%\n",
      "Step 85: loss = 0.144 metric = 98.27%\n",
      "Step 86: loss = 0.142 metric = 98.34%\n",
      "Step 87: loss = 0.14 metric = 98.34%\n",
      "Step 88: loss = 0.138 metric = 98.45%\n",
      "Step 89: loss = 0.136 metric = 98.50%\n",
      "Step 90: loss = 0.133 metric = 98.57%\n",
      "Step 91: loss = 0.13 metric = 98.66%\n",
      "Step 92: loss = 0.128 metric = 98.72%\n",
      "Step 93: loss = 0.126 metric = 98.75%\n",
      "Step 94: loss = 0.124 metric = 98.82%\n",
      "Step 95: loss = 0.122 metric = 98.84%\n",
      "Step 96: loss = 0.12 metric = 98.84%\n",
      "Step 97: loss = 0.119 metric = 98.84%\n",
      "Step 98: loss = 0.118 metric = 98.86%\n",
      "Step 99: loss = 0.117 metric = 98.86%\n",
      "Step 100: loss = 0.115 metric = 98.88%\n",
      "Step 101: loss = 0.114 metric = 98.88%\n",
      "Step 102: loss = 0.113 metric = 98.88%\n",
      "Step 103: loss = 0.112 metric = 98.88%\n",
      "Step 104: loss = 0.111 metric = 98.91%\n",
      "Step 105: loss = 0.109 metric = 98.93%\n",
      "Step 106: loss = 0.108 metric = 98.93%\n",
      "Step 107: loss = 0.107 metric = 98.93%\n",
      "Step 108: loss = 0.105 metric = 98.95%\n",
      "Step 109: loss = 0.103 metric = 99.00%\n",
      "Step 110: loss = 0.102 metric = 99.00%\n",
      "Step 111: loss = 0.101 metric = 99.07%\n",
      "Step 112: loss = 0.0997 metric = 99.07%\n",
      "Step 113: loss = 0.0989 metric = 99.07%\n",
      "Step 114: loss = 0.0981 metric = 99.07%\n",
      "Step 115: loss = 0.0972 metric = 99.07%\n",
      "Step 116: loss = 0.0964 metric = 99.09%\n",
      "Step 117: loss = 0.0955 metric = 99.09%\n",
      "Step 118: loss = 0.0945 metric = 99.09%\n",
      "Step 119: loss = 0.0927 metric = 99.13%\n",
      "Step 120: loss = 0.0911 metric = 99.16%\n",
      "Step 121: loss = 0.0898 metric = 99.18%\n",
      "Step 122: loss = 0.0888 metric = 99.20%\n",
      "Step 123: loss = 0.0879 metric = 99.23%\n",
      "Step 124: loss = 0.0872 metric = 99.23%\n",
      "Step 125: loss = 0.0865 metric = 99.25%\n",
      "Step 126: loss = 0.0856 metric = 99.25%\n",
      "Step 127: loss = 0.0846 metric = 99.27%\n",
      "Step 128: loss = 0.0839 metric = 99.29%\n",
      "Step 129: loss = 0.0831 metric = 99.29%\n",
      "Step 130: loss = 0.0822 metric = 99.29%\n",
      "Step 131: loss = 0.0809 metric = 99.32%\n",
      "Step 132: loss = 0.0791 metric = 99.36%\n",
      "Step 133: loss = 0.0772 metric = 99.39%\n",
      "Step 134: loss = 0.0761 metric = 99.43%\n",
      "Step 135: loss = 0.0758 metric = 99.41%\n",
      "Step 136: loss = 0.0751 metric = 99.43%\n",
      "Step 137: loss = 0.0747 metric = 99.43%\n",
      "Step 138: loss = 0.0749 metric = 99.41%\n",
      "Step 139: loss = 0.073 metric = 99.43%\n",
      "Step 140: loss = 0.0726 metric = 99.43%\n",
      "Step 141: loss = 0.0718 metric = 99.43%\n",
      "Step 142: loss = 0.0708 metric = 99.45%\n",
      "Step 143: loss = 0.07 metric = 99.45%\n",
      "Step 144: loss = 0.0697 metric = 99.45%\n",
      "Step 145: loss = 0.0693 metric = 99.45%\n",
      "Step 146: loss = 0.0685 metric = 99.45%\n",
      "Step 147: loss = 0.0678 metric = 99.45%\n",
      "Step 148: loss = 0.067 metric = 99.48%\n",
      "Step 149: loss = 0.0659 metric = 99.50%\n",
      "Step 150: loss = 0.0652 metric = 99.54%\n",
      "Step 151: loss = 0.0647 metric = 99.54%\n",
      "Step 152: loss = 0.0635 metric = 99.57%\n",
      "Step 153: loss = 0.063 metric = 99.57%\n",
      "Step 154: loss = 0.0625 metric = 99.57%\n",
      "Step 155: loss = 0.0621 metric = 99.57%\n",
      "Step 156: loss = 0.0615 metric = 99.57%\n",
      "Step 157: loss = 0.0609 metric = 99.59%\n",
      "Step 158: loss = 0.0604 metric = 99.59%\n",
      "Step 159: loss = 0.06 metric = 99.59%\n",
      "Step 160: loss = 0.0595 metric = 99.59%\n",
      "Step 161: loss = 0.059 metric = 99.59%\n",
      "Step 162: loss = 0.0583 metric = 99.61%\n",
      "Step 163: loss = 0.058 metric = 99.61%\n",
      "Step 164: loss = 0.0576 metric = 99.61%\n",
      "Step 165: loss = 0.0572 metric = 99.61%\n",
      "Step 166: loss = 0.0569 metric = 99.61%\n",
      "Step 167: loss = 0.0565 metric = 99.61%\n",
      "Step 168: loss = 0.0562 metric = 99.61%\n",
      "Step 169: loss = 0.0559 metric = 99.61%\n",
      "Step 170: loss = 0.0555 metric = 99.61%\n",
      "Step 171: loss = 0.0552 metric = 99.61%\n",
      "Step 172: loss = 0.0549 metric = 99.61%\n",
      "Step 173: loss = 0.0546 metric = 99.61%\n",
      "Step 174: loss = 0.0543 metric = 99.61%\n",
      "Step 175: loss = 0.0539 metric = 99.61%\n",
      "Step 176: loss = 0.0536 metric = 99.61%\n",
      "Step 177: loss = 0.0533 metric = 99.61%\n",
      "Step 178: loss = 0.053 metric = 99.61%\n",
      "Step 179: loss = 0.0526 metric = 99.61%\n",
      "Step 180: loss = 0.0523 metric = 99.61%\n",
      "Step 181: loss = 0.0519 metric = 99.64%\n",
      "Step 182: loss = 0.0516 metric = 99.64%\n",
      "Step 183: loss = 0.0513 metric = 99.64%\n",
      "Step 184: loss = 0.051 metric = 99.64%\n",
      "Step 185: loss = 0.0507 metric = 99.64%\n",
      "Step 186: loss = 0.0504 metric = 99.64%\n",
      "Step 187: loss = 0.0502 metric = 99.64%\n",
      "Step 188: loss = 0.0498 metric = 99.64%\n",
      "Step 189: loss = 0.0494 metric = 99.64%\n",
      "Step 190: loss = 0.0485 metric = 99.64%\n",
      "Step 191: loss = 0.048 metric = 99.66%\n",
      "Step 192: loss = 0.0478 metric = 99.66%\n",
      "Step 193: loss = 0.0476 metric = 99.66%\n",
      "Step 194: loss = 0.0473 metric = 99.66%\n",
      "Step 195: loss = 0.047 metric = 99.66%\n",
      "Step 196: loss = 0.0467 metric = 99.66%\n",
      "Step 197: loss = 0.0465 metric = 99.66%\n",
      "Step 198: loss = 0.0462 metric = 99.66%\n",
      "Step 199: loss = 0.046 metric = 99.66%\n",
      "Step 200: loss = 0.0457 metric = 99.66%\n",
      "Step 201: loss = 0.0454 metric = 99.66%\n",
      "Step 202: loss = 0.0451 metric = 99.66%\n",
      "Step 203: loss = 0.0448 metric = 99.68%\n",
      "Step 204: loss = 0.0441 metric = 99.68%\n",
      "Step 205: loss = 0.0434 metric = 99.70%\n",
      "Step 206: loss = 0.0432 metric = 99.70%\n",
      "Step 207: loss = 0.0428 metric = 99.70%\n",
      "Step 208: loss = 0.0424 metric = 99.73%\n",
      "Step 209: loss = 0.0422 metric = 99.73%\n",
      "Step 210: loss = 0.042 metric = 99.73%\n",
      "Step 211: loss = 0.0418 metric = 99.73%\n",
      "Step 212: loss = 0.0416 metric = 99.73%\n",
      "Step 213: loss = 0.0413 metric = 99.73%\n",
      "Step 214: loss = 0.0411 metric = 99.73%\n",
      "Step 215: loss = 0.0409 metric = 99.73%\n",
      "Step 216: loss = 0.0407 metric = 99.73%\n",
      "Step 217: loss = 0.0402 metric = 99.73%\n",
      "Step 218: loss = 0.0391 metric = 99.75%\n",
      "Step 219: loss = 0.039 metric = 99.75%\n",
      "Step 220: loss = 0.0386 metric = 99.75%\n",
      "Step 221: loss = 0.0384 metric = 99.75%\n",
      "Step 222: loss = 0.0381 metric = 99.75%\n",
      "Step 223: loss = 0.038 metric = 99.77%\n",
      "Step 224: loss = 0.0378 metric = 99.77%\n",
      "Step 225: loss = 0.0376 metric = 99.77%\n",
      "Step 226: loss = 0.0373 metric = 99.77%\n",
      "Step 227: loss = 0.0371 metric = 99.77%\n",
      "Step 228: loss = 0.0369 metric = 99.77%\n",
      "Step 229: loss = 0.0367 metric = 99.77%\n",
      "Step 230: loss = 0.0365 metric = 99.77%\n",
      "Step 231: loss = 0.0362 metric = 99.77%\n",
      "Step 232: loss = 0.036 metric = 99.80%\n",
      "Step 233: loss = 0.0358 metric = 99.80%\n",
      "Step 234: loss = 0.0355 metric = 99.80%\n",
      "Step 235: loss = 0.0353 metric = 99.80%\n",
      "Step 236: loss = 0.0352 metric = 99.80%\n",
      "Step 237: loss = 0.035 metric = 99.80%\n",
      "Step 238: loss = 0.0348 metric = 99.82%\n",
      "Step 239: loss = 0.0346 metric = 99.82%\n",
      "Step 240: loss = 0.0345 metric = 99.82%\n",
      "Step 241: loss = 0.0343 metric = 99.82%\n",
      "Step 242: loss = 0.0341 metric = 99.82%\n",
      "Step 243: loss = 0.0339 metric = 99.82%\n",
      "Step 244: loss = 0.0338 metric = 99.82%\n",
      "Step 245: loss = 0.0336 metric = 99.82%\n",
      "Step 246: loss = 0.0335 metric = 99.82%\n",
      "Step 247: loss = 0.0333 metric = 99.82%\n",
      "Step 248: loss = 0.0331 metric = 99.82%\n",
      "Step 249: loss = 0.033 metric = 99.82%\n",
      "Step 250: loss = 0.0328 metric = 99.82%\n",
      "Step 251: loss = 0.0327 metric = 99.82%\n",
      "Step 252: loss = 0.0325 metric = 99.82%\n",
      "Step 253: loss = 0.0324 metric = 99.82%\n",
      "Step 254: loss = 0.0322 metric = 99.82%\n",
      "Step 255: loss = 0.0321 metric = 99.82%\n",
      "Step 256: loss = 0.0319 metric = 99.82%\n",
      "Step 257: loss = 0.0318 metric = 99.82%\n",
      "Step 258: loss = 0.0316 metric = 99.82%\n",
      "Step 259: loss = 0.0315 metric = 99.82%\n",
      "Step 260: loss = 0.0314 metric = 99.82%\n",
      "Step 261: loss = 0.0312 metric = 99.82%\n",
      "Step 262: loss = 0.0311 metric = 99.82%\n",
      "Step 263: loss = 0.031 metric = 99.82%\n",
      "Step 264: loss = 0.0308 metric = 99.82%\n",
      "Step 265: loss = 0.0307 metric = 99.82%\n",
      "Step 266: loss = 0.0306 metric = 99.82%\n",
      "Step 267: loss = 0.0304 metric = 99.82%\n",
      "Step 268: loss = 0.0303 metric = 99.82%\n",
      "Step 269: loss = 0.0302 metric = 99.82%\n",
      "Step 270: loss = 0.0301 metric = 99.82%\n",
      "Step 271: loss = 0.0299 metric = 99.82%\n",
      "Step 272: loss = 0.0298 metric = 99.82%\n",
      "Step 273: loss = 0.0297 metric = 99.82%\n",
      "Step 274: loss = 0.0296 metric = 99.82%\n",
      "Step 275: loss = 0.0294 metric = 99.82%\n",
      "Step 276: loss = 0.0293 metric = 99.82%\n",
      "Step 277: loss = 0.0292 metric = 99.82%\n",
      "Step 278: loss = 0.0291 metric = 99.82%\n",
      "Step 279: loss = 0.0289 metric = 99.82%\n",
      "Step 280: loss = 0.0288 metric = 99.82%\n",
      "Step 281: loss = 0.0287 metric = 99.82%\n",
      "Step 282: loss = 0.0285 metric = 99.82%\n",
      "Step 283: loss = 0.0282 metric = 99.82%\n",
      "Step 284: loss = 0.0278 metric = 99.84%\n",
      "Step 285: loss = 0.0277 metric = 99.84%\n",
      "Step 286: loss = 0.0275 metric = 99.84%\n",
      "Step 287: loss = 0.0274 metric = 99.84%\n",
      "Step 288: loss = 0.0274 metric = 99.84%\n",
      "Step 289: loss = 0.0273 metric = 99.84%\n",
      "Step 290: loss = 0.0286 metric = 99.82%\n",
      "Step 291: loss = 0.0273 metric = 99.84%\n",
      "Step 292: loss = 0.0271 metric = 99.84%\n",
      "Step 293: loss = 0.0273 metric = 99.84%\n",
      "Step 294: loss = 0.0269 metric = 99.84%\n",
      "Step 295: loss = 0.0267 metric = 99.84%\n",
      "Step 296: loss = 0.0267 metric = 99.84%\n",
      "Step 297: loss = 0.0265 metric = 99.84%\n",
      "Step 298: loss = 0.0264 metric = 99.84%\n",
      "Step 299: loss = 0.0263 metric = 99.84%\n",
      "Step 300: loss = 0.0263 metric = 99.84%\n",
      "Step 301: loss = 0.026 metric = 99.84%\n",
      "Step 302: loss = 0.026 metric = 99.84%\n",
      "Step 303: loss = 0.026 metric = 99.84%\n",
      "Step 304: loss = 0.0258 metric = 99.84%\n",
      "Step 305: loss = 0.0257 metric = 99.82%\n",
      "Step 306: loss = 0.0256 metric = 99.84%\n",
      "Step 307: loss = 0.0255 metric = 99.84%\n",
      "Step 308: loss = 0.0254 metric = 99.82%\n",
      "Step 309: loss = 0.0252 metric = 99.84%\n",
      "Step 310: loss = 0.0253 metric = 99.82%\n",
      "Step 311: loss = 0.0252 metric = 99.82%\n",
      "Step 312: loss = 0.0251 metric = 99.82%\n",
      "Step 313: loss = 0.025 metric = 99.82%\n",
      "Step 314: loss = 0.0248 metric = 99.84%\n",
      "Step 315: loss = 0.0247 metric = 99.84%\n",
      "Step 316: loss = 0.0246 metric = 99.84%\n",
      "Step 317: loss = 0.0245 metric = 99.84%\n",
      "Step 318: loss = 0.0244 metric = 99.84%\n",
      "Step 319: loss = 0.0243 metric = 99.84%\n",
      "Step 320: loss = 0.0242 metric = 99.84%\n",
      "Step 321: loss = 0.0241 metric = 99.84%\n",
      "Step 322: loss = 0.024 metric = 99.84%\n",
      "Step 323: loss = 0.0239 metric = 99.84%\n",
      "Step 324: loss = 0.0238 metric = 99.84%\n",
      "Step 325: loss = 0.0237 metric = 99.84%\n",
      "Step 326: loss = 0.0237 metric = 99.84%\n",
      "Step 327: loss = 0.0236 metric = 99.84%\n",
      "Step 328: loss = 0.0235 metric = 99.84%\n",
      "Step 329: loss = 0.0234 metric = 99.84%\n",
      "Step 330: loss = 0.0233 metric = 99.84%\n",
      "Step 331: loss = 0.0232 metric = 99.84%\n",
      "Step 332: loss = 0.0231 metric = 99.84%\n",
      "Step 333: loss = 0.0231 metric = 99.84%\n",
      "Step 334: loss = 0.023 metric = 99.84%\n",
      "Step 335: loss = 0.0229 metric = 99.84%\n",
      "Step 336: loss = 0.0228 metric = 99.84%\n",
      "Step 337: loss = 0.0227 metric = 99.84%\n",
      "Step 338: loss = 0.0227 metric = 99.84%\n",
      "Step 339: loss = 0.0226 metric = 99.84%\n",
      "Step 340: loss = 0.0225 metric = 99.84%\n",
      "Step 341: loss = 0.0224 metric = 99.84%\n",
      "Step 342: loss = 0.0223 metric = 99.84%\n",
      "Step 343: loss = 0.0223 metric = 99.84%\n",
      "Step 344: loss = 0.0222 metric = 99.84%\n",
      "Step 345: loss = 0.0221 metric = 99.84%\n",
      "Step 346: loss = 0.022 metric = 99.84%\n",
      "Step 347: loss = 0.022 metric = 99.84%\n",
      "Step 348: loss = 0.0219 metric = 99.84%\n",
      "Step 349: loss = 0.0218 metric = 99.84%\n",
      "Step 350: loss = 0.0218 metric = 99.84%\n",
      "Step 351: loss = 0.0217 metric = 99.84%\n",
      "Step 352: loss = 0.0217 metric = 99.84%\n",
      "Step 353: loss = 0.0216 metric = 99.84%\n",
      "Step 354: loss = 0.0215 metric = 99.84%\n",
      "Step 355: loss = 0.0215 metric = 99.84%\n",
      "Step 356: loss = 0.0214 metric = 99.84%\n",
      "Step 357: loss = 0.0213 metric = 99.84%\n",
      "Step 358: loss = 0.0212 metric = 99.84%\n",
      "Step 359: loss = 0.0211 metric = 99.84%\n",
      "Step 360: loss = 0.0211 metric = 99.84%\n",
      "Step 361: loss = 0.021 metric = 99.84%\n",
      "Step 362: loss = 0.0209 metric = 99.84%\n",
      "Step 363: loss = 0.0209 metric = 99.84%\n",
      "Step 364: loss = 0.0208 metric = 99.84%\n",
      "Step 365: loss = 0.0208 metric = 99.84%\n",
      "Step 366: loss = 0.0207 metric = 99.84%\n",
      "Step 367: loss = 0.0206 metric = 99.84%\n",
      "Step 368: loss = 0.0205 metric = 99.84%\n",
      "Step 369: loss = 0.0205 metric = 99.84%\n",
      "Step 370: loss = 0.0204 metric = 99.84%\n",
      "Step 371: loss = 0.0203 metric = 99.84%\n",
      "Step 372: loss = 0.0203 metric = 99.84%\n",
      "Step 373: loss = 0.0202 metric = 99.84%\n",
      "Step 374: loss = 0.0201 metric = 99.84%\n",
      "Step 375: loss = 0.0201 metric = 99.84%\n",
      "Step 376: loss = 0.02 metric = 99.84%\n",
      "Step 377: loss = 0.0199 metric = 99.84%\n",
      "Step 378: loss = 0.0199 metric = 99.84%\n",
      "Step 379: loss = 0.0198 metric = 99.84%\n",
      "Step 380: loss = 0.0198 metric = 99.84%\n",
      "Step 381: loss = 0.0197 metric = 99.84%\n",
      "Step 382: loss = 0.0197 metric = 99.84%\n",
      "Step 383: loss = 0.0196 metric = 99.84%\n",
      "Step 384: loss = 0.0196 metric = 99.84%\n",
      "early stoping\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(len(labels), tokenizer, 4, 16, 8)\n",
    "model.to(\"cuda:0\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.0E-3)\n",
    "train = Batchifyer(df_train, tokenizer, n_batches=1, batch_size=None)\n",
    "val = Batchifyer(df_val, tokenizer, n_batches=1, batch_size=None)\n",
    "train_loop(model, optimizer, train, val, n_steps=1000, patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 99.863%\n"
     ]
    }
   ],
   "source": [
    "X, Y = data_to_tensor(df_test, tokenizer)\n",
    "y_pred = model.predict(X)\n",
    "acc = accuracy(y_pred, Y.to(y_pred.device))\n",
    "print(f\"accuracy {acc:.3%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2017a09ab1f54c7a6a1af190715fd60264df4a93389a277e03c18d947a6e489"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
